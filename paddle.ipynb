{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip -q install paddlepaddle -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
        "\n",
        "# 验证\n",
        "import paddle\n",
        "paddle.utils.run_check()\n",
        "print(\"Paddle version:\", paddle.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awQrZ0Q-NF7S",
        "outputId": "3265d07e-b0d1-41b4-921c-e52935268ef6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.0/189.0 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
            "  warnings.warn(warning_message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running verify PaddlePaddle program ... \n",
            "PaddlePaddle works well on 1 CPU.\n",
            "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n",
            "Paddle version: 3.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/pir/math_op_patch.py:219: UserWarning: Value do not have 'place' interface for pir graph mode, try not to use it. None will be returned.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Literal, Optional\n",
        "\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "\n",
        "# ---------- 通用初始化 ------------------------------------------------------\n",
        "def init_rsqrt_uniform_(w: paddle.Tensor) -> paddle.Tensor:\n",
        "    bound = 1.0 / math.sqrt(w.shape[-1])\n",
        "    noise = paddle.uniform(w.shape, min=-bound, max=bound, dtype=w.dtype)\n",
        "    w.set_value(noise)\n",
        "    return w\n",
        "\n",
        "def init_random_signs_(w: paddle.Tensor) -> paddle.Tensor:\n",
        "    # 0/1 伯努利 -> *2 -1  => {-1, +1}\n",
        "    with paddle.no_grad():\n",
        "        p = paddle.full(w.shape, 0.5, dtype='float32')\n",
        "        s = paddle.bernoulli(p) * 2.0 - 1.0\n",
        "        s = paddle.cast(s, w.dtype)\n",
        "        w.set_value(s)\n",
        "    return w\n",
        "\n",
        "# ---------- 基础层 ----------------------------------------------------------\n",
        "class NLinear(nn.Layer):\n",
        "    \"\"\"PackedEnsemble: K 份 Linear 打包 → 输入 (B,K,D), 权重布局 (K, I, O)\"\"\"\n",
        "    def __init__(self, k: int, in_f: int, out_f: int, bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.in_f = in_f\n",
        "        self.out_f = out_f\n",
        "        # 按 Paddle 线性层布局 [I, O]\n",
        "        self.weight = self.create_parameter(shape=[k, in_f, out_f])\n",
        "        self.bias_e = self.create_parameter(shape=[k, out_f]) if bias else None\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init_rsqrt_uniform_(self.weight)\n",
        "        if self.bias_e is not None:\n",
        "            init_rsqrt_uniform_(self.bias_e)\n",
        "\n",
        "    def forward(self, x):                 # x: (B,K,D=I)\n",
        "        # 转成 (K,B,D) 与 batched matmul 对齐\n",
        "        xk = paddle.transpose(x, [1, 0, 2])           # (K,B,I)\n",
        "        # (K,B,I) @ (K,I,O) = (K,B,O)\n",
        "        yk = paddle.bmm(xk, self.weight)              # (K,B,O)\n",
        "        y = paddle.transpose(yk, [1, 0, 2])           # (B,K,O)\n",
        "        if self.bias_e is not None:\n",
        "            y = y + self.bias_e                       # 广播到 (B,K,O)\n",
        "        return y\n",
        "\n",
        "class ScaleEnsemble(nn.Layer):\n",
        "    \"\"\"Mini-Ensemble：每层一个 rank-1 缩放向量\"\"\"\n",
        "    def __init__(self, k: int, d: int, init='ones'):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.d = d\n",
        "        self.init = init\n",
        "        self.weight = self.create_parameter(shape=[k, d])\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        if self.init == 'ones':\n",
        "            self.weight.set_value(paddle.ones_like(self.weight))\n",
        "        else:\n",
        "            init_random_signs_(self.weight)\n",
        "\n",
        "    def forward(self, x):                 # (B,K,D)\n",
        "        return x * self.weight            # 广播到 (B,K,D)\n",
        "\n",
        "class LinearBE(nn.Layer):\n",
        "    \"\"\"\n",
        "    BatchEnsemble Linear（Paddle 布局）：\n",
        "        权重 W: [I, O]；前向 y_e = ((x * r_e) @ W) * s_e + b_e\n",
        "    输入:  x (B,K,I)\n",
        "    输出:  y (B,K,O)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_f: int, out_f: int, k: int,\n",
        "                 scale_init='ones', bias: bool = True):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.in_f = in_f\n",
        "        self.out_f = out_f\n",
        "        # 显式属性名，避免冲突；按 Paddle 线性层布局 [I, O]\n",
        "        self.weight = self.create_parameter(shape=[in_f, out_f])\n",
        "        self.r = self.create_parameter(shape=[k, in_f])\n",
        "        self.s = self.create_parameter(shape=[k, out_f])\n",
        "        self.use_bias = bias\n",
        "        self.bias_e = self.create_parameter(shape=[k, out_f]) if bias else None\n",
        "        self.scale_init = scale_init\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        init_rsqrt_uniform_(self.weight)\n",
        "        if self.scale_init == 'ones':\n",
        "            self.r.set_value(paddle.ones_like(self.r))\n",
        "            self.s.set_value(paddle.ones_like(self.s))\n",
        "        else:\n",
        "            init_random_signs_(self.r)\n",
        "            init_random_signs_(self.s)\n",
        "        if self.use_bias:\n",
        "            init_rsqrt_uniform_(self.bias_e)\n",
        "\n",
        "    def forward(self, x):                 # (B,K,I)\n",
        "        xr = x * self.r                                  # (B,K,I)\n",
        "        # (B,K,I) @ (I,O) = (B,K,O)\n",
        "        y = paddle.matmul(xr, self.weight)               # (B,K,O)\n",
        "        y = y * self.s                                   # (B,K,O)\n",
        "        if self.use_bias:\n",
        "            y = y + self.bias_e\n",
        "        return y\n",
        "\n",
        "# ---------- Backbone MLP -----------------------------------------------------\n",
        "class MLPBlock(nn.Layer):\n",
        "    def __init__(self, d_in, d_hid, dropout, act='ReLU'):\n",
        "        super().__init__()\n",
        "        Act = getattr(nn, act)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_in, d_hid),   # Paddle: weight [d_in, d_hid]\n",
        "            Act(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 允许 (B,K,D) 或 (B,D)；Linear 会在最后一维上工作\n",
        "        return self.net(x)\n",
        "\n",
        "class BackboneMLP(nn.Layer):\n",
        "    def __init__(self, n_blocks: int, d_in: int, d_hidden: int, dropout: float):\n",
        "        super().__init__()\n",
        "        blocks = []\n",
        "        for i in range(n_blocks):\n",
        "            blocks.append(\n",
        "                MLPBlock(d_in if i == 0 else d_hidden, d_hidden, dropout)\n",
        "            )\n",
        "        self.blocks = nn.LayerList(blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        return x\n",
        "\n",
        "# ---------- 工具：递归替换 Linear 为 BE / Packed ---------------------------\n",
        "def _get_parent_by_path(root: nn.Layer, path_list):\n",
        "    \"\"\"根据命名路径拿到父层（最后一个名是子层名）\"\"\"\n",
        "    cur = root\n",
        "    for p in path_list:\n",
        "        if hasattr(cur, p):\n",
        "            cur = getattr(cur, p)\n",
        "        else:\n",
        "            sub_layers = getattr(cur, \"_sub_layers\", None)\n",
        "            if sub_layers is None or p not in sub_layers:\n",
        "                raise AttributeError(f\"Cannot locate sublayer '{p}' under '{type(cur).__name__}'\")\n",
        "            cur = sub_layers[p]\n",
        "    return cur\n",
        "\n",
        "def _replace_linear(module: nn.Layer, k: int, mode: Literal['be', 'packed']):\n",
        "    \"\"\"\n",
        "    遍历 module 的子层，把 nn.Linear 替换为 LinearBE 或 NLinear\n",
        "    注意：Paddle Linear 的 weight 形状为 [in_features, out_features]\n",
        "    \"\"\"\n",
        "    to_replace = []\n",
        "\n",
        "    for full_name, layer in module.named_sublayers(include_self=False):\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            parts = full_name.split('.')\n",
        "            parent_path, child_name = parts[:-1], parts[-1]\n",
        "            parent = _get_parent_by_path(module, parent_path) if parent_path else module\n",
        "\n",
        "            in_f  = layer.weight.shape[0]  # I\n",
        "            out_f = layer.weight.shape[1]  # O\n",
        "\n",
        "            if mode == 'be':\n",
        "                new_layer = LinearBE(in_f, out_f, k)\n",
        "                with paddle.no_grad():\n",
        "                    # 拷贝共享主权重（[I,O]）与偏置（[O]）\n",
        "                    assert list(new_layer.weight.shape) == list(layer.weight.shape), \\\n",
        "                        f\"weight shape mismatch: {new_layer.weight.shape} vs {layer.weight.shape}\"\n",
        "                    new_layer.weight.set_value(layer.weight.clone())\n",
        "                    if layer.bias is not None and new_layer.bias_e is not None:\n",
        "                        b = layer.bias.reshape([1, -1]).tile([k, 1])  # (K, O)\n",
        "                        assert list(new_layer.bias_e.shape) == list(b.shape), \\\n",
        "                            f\"bias shape mismatch: {new_layer.bias_e.shape} vs {b.shape}\"\n",
        "                        new_layer.bias_e.set_value(b)\n",
        "            else:  # 'packed'\n",
        "                new_layer = NLinear(k, in_f, out_f, bias=layer.bias is not None)\n",
        "                with paddle.no_grad():\n",
        "                    # 每个 pack 共享同一权重初值: 原 (I,O) -> (K,I,O)\n",
        "                    w = layer.weight.unsqueeze(0).tile([k, 1, 1])  # (K,I,O)\n",
        "                    assert list(new_layer.weight.shape) == list(w.shape), \\\n",
        "                        f\"packed weight shape mismatch: {new_layer.weight.shape} vs {w.shape}\"\n",
        "                    new_layer.weight.set_value(w)\n",
        "                    if layer.bias is not None and new_layer.bias_e is not None:\n",
        "                        b = layer.bias.unsqueeze(0).tile([k, 1])    # (K,O)\n",
        "                        assert list(new_layer.bias_e.shape) == list(b.shape), \\\n",
        "                            f\"packed bias shape mismatch: {new_layer.bias_e.shape} vs {b.shape}\"\n",
        "                        new_layer.bias_e.set_value(b)\n",
        "\n",
        "            to_replace.append((parent, child_name, new_layer))\n",
        "\n",
        "    # 正式替换\n",
        "    for parent, child_name, new_layer in to_replace:\n",
        "        if hasattr(parent, child_name):\n",
        "            setattr(parent, child_name, new_layer)\n",
        "        else:\n",
        "            sub_layers = getattr(parent, \"_sub_layers\", None)\n",
        "            if sub_layers is None or child_name not in sub_layers:\n",
        "                raise AttributeError(f\"Cannot set sublayer '{child_name}' under '{type(parent).__name__}'\")\n",
        "            parent._sub_layers[child_name] = new_layer\n",
        "\n",
        "# ---------- TabM 特征提取器 --------------------------------------------------\n",
        "class TabMFeatureExtractor(nn.Layer):\n",
        "    \"\"\"\n",
        "    arch_type: 'plain' | 'tabm' | 'tabm-mini' | 'tabm-packed'\n",
        "    返回：\n",
        "        - reduce=True  → (B,H)\n",
        "        - reduce=False → (B,K,H)\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 num_features: int,\n",
        "                 arch_type: Literal['plain', 'tabm', 'tabm-mini', 'tabm-packed']='tabm',\n",
        "                 k: int = 32,\n",
        "                 backbone_cfg: Optional[dict] = None,\n",
        "                 reduce: bool = True):\n",
        "        super().__init__()\n",
        "        if arch_type == 'plain':\n",
        "            k = 1\n",
        "        self.k = k\n",
        "        self.reduce = reduce\n",
        "        cfg = backbone_cfg or dict(n_blocks=3, d_hidden=512, dropout=0.1)\n",
        "        self.backbone = BackboneMLP(**cfg, d_in=num_features)\n",
        "\n",
        "        # --- 插入 Ensemble 逻辑 ---\n",
        "        if arch_type == 'tabm':\n",
        "            _replace_linear(self.backbone, k, mode='be')\n",
        "            self.min_adapter = None\n",
        "        elif arch_type == 'tabm-mini':\n",
        "            self.min_adapter = ScaleEnsemble(k, num_features, init='random-signs')\n",
        "        elif arch_type == 'tabm-packed':\n",
        "            _replace_linear(self.backbone, k, mode='packed')\n",
        "            self.min_adapter = None\n",
        "        else:  # plain\n",
        "            self.min_adapter = None\n",
        "\n",
        "    def forward(self, x_num: paddle.Tensor):\n",
        "        \"\"\"\n",
        "        x_num : (B, num_features) – 已完成数值化/标准化\n",
        "        \"\"\"\n",
        "        if self.k > 1:\n",
        "            x = x_num.unsqueeze(1).tile([1, self.k, 1])  # (B,K,D)\n",
        "        else:\n",
        "            x = x_num.unsqueeze(1)                        # (B,1,D)\n",
        "\n",
        "        if self.min_adapter is not None:\n",
        "            x = self.min_adapter(x)                       # (B,K,D)\n",
        "\n",
        "        features = self.backbone(x)                       # (B,K,H)\n",
        "        if self.reduce:\n",
        "            return features.mean(axis=1)                  # (B,H)\n",
        "        return features                                   # (B,K,H)\n",
        "\n",
        "# ---------------- Quick check ----------------\n",
        "if __name__ == '__main__':\n",
        "    paddle.seed(123)\n",
        "    B, D = 8, 30\n",
        "    x = paddle.randn([B, D])\n",
        "    # 1) 标准 TabM（BatchEnsemble 替换）\n",
        "    fe1 = TabMFeatureExtractor(D, arch_type='tabm', k=16, reduce=True)\n",
        "    out1 = fe1(x)\n",
        "    print('TabM-BE features:', list(out1.shape))   # (B, H)\n",
        "\n",
        "    # 2) tabm-mini（只做 rank-1 缩放）\n",
        "    fe2 = TabMFeatureExtractor(D, arch_type='tabm-mini', k=16, reduce=False)\n",
        "    out2 = fe2(x)\n",
        "    print('TabM-mini features:', list(out2.shape)) # (B, K, H)\n",
        "\n",
        "    # 3) tabm-packed（Packed NLinear）\n",
        "    fe3 = TabMFeatureExtractor(D, arch_type='tabm-packed', k=8, reduce=True)\n",
        "    out3 = fe3(x)\n",
        "    print('TabM-packed features:', list(out3.shape)) # (B, H)\n",
        "\n",
        "    # 4) plain（无集成基线）\n",
        "    fe4 = TabMFeatureExtractor(D, arch_type='plain', k=1, reduce=True)\n",
        "    out4 = fe4(x)\n",
        "    print('Plain features:', list(out4.shape))     # (B, H)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCF5hoiWF-N4",
        "outputId": "df4ea66c-1716-4357-fa58-fb5f8f57d183"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM-BE features: [8, 512]\n",
            "TabM-mini features: [8, 16, 512]\n",
            "TabM-packed features: [8, 512]\n",
            "Plain features: [8, 512]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import math\n",
        "from typing import Optional, Literal, Tuple\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "from paddle.io import Dataset, DataLoader\n",
        "\n",
        "\n",
        "# ====== 数据集（示例：合成数据）========================================\n",
        "class ToyMultiLabelDataset(Dataset):\n",
        "    \"\"\"\n",
        "    返回:\n",
        "      x_num: float32, 形状 (D,)\n",
        "      y:     float32, 形状 (4,)  —— 多标签 0/1\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, d: int, seed: int = 123):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.X = rng.normal(size=(n, d)).astype('float32')\n",
        "        # 随机生成 4 个线性规则 + 噪声，得到多标签\n",
        "        W = rng.normal(size=(d, 4))\n",
        "        logits = self.X @ W + rng.normal(scale=0.5, size=(n, 4))\n",
        "        probs  = 1.0 / (1.0 + np.exp(-logits))\n",
        "        self.Y = (probs > 0.5).astype('float32')\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.X)\n",
        "\n",
        "# ====== 模型：特征抽取 + 多标签头 ======================================\n",
        "class MultiLabelClassifier(nn.Layer):\n",
        "    def __init__(self, num_features: int, num_labels: int = 4,\n",
        "                 arch_type: str = 'tabm', k: int = 16,\n",
        "                 backbone_cfg: Optional[dict] = None):\n",
        "        super().__init__()\n",
        "        self.fe = TabMFeatureExtractor(\n",
        "            num_features=num_features,\n",
        "            arch_type=arch_type,\n",
        "            k=k,\n",
        "            backbone_cfg=backbone_cfg,\n",
        "            reduce=True\n",
        "        )\n",
        "        # 推断隐藏维度（若你的 TabM 有属性可读，直接使用；否则手动传入）\n",
        "        d_hidden = getattr(self.fe, \"d_hidden\", (backbone_cfg or dict(d_hidden=512))[\"d_hidden\"])\n",
        "        self.head = nn.Linear(d_hidden, num_labels)\n",
        "\n",
        "    def forward(self, x_num: paddle.Tensor) -> paddle.Tensor:\n",
        "        # x_num: (B, D)\n",
        "        h = self.fe(x_num)           # (B, H)\n",
        "        logits = self.head(h)        # (B, 4)\n",
        "        return logits\n",
        "\n",
        "# ====== 评价指标：F1、AP 等 ==============================================\n",
        "def f1_per_class(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-9) -> Tuple[np.ndarray, float, float]:\n",
        "    \"\"\"\n",
        "    y_true: (N, C) 0/1\n",
        "    y_pred: (N, C) 0/1\n",
        "    返回: per_class F1, macro-F1, micro-F1\n",
        "    \"\"\"\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    N, C = y_true.shape\n",
        "    f1_c = np.zeros(C, dtype=np.float32)\n",
        "\n",
        "    # per-class\n",
        "    for c in range(C):\n",
        "        yt = y_true[:, c]\n",
        "        yp = y_pred[:, c]\n",
        "        tp = np.sum((yt == 1) & (yp == 1))\n",
        "        fp = np.sum((yt == 0) & (yp == 1))\n",
        "        fn = np.sum((yt == 1) & (yp == 0))\n",
        "        prec = tp / (tp + fp + eps)\n",
        "        rec  = tp / (tp + fn + eps)\n",
        "        f1_c[c] = 2 * prec * rec / (prec + rec + eps)\n",
        "\n",
        "    macro_f1 = float(np.mean(f1_c))\n",
        "\n",
        "    # micro\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    prec = tp / (tp + fp + 1e-9)\n",
        "    rec  = tp / (tp + fn + 1e-9)\n",
        "    micro_f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "    return f1_c, macro_f1, float(micro_f1)\n",
        "\n",
        "def average_precision_micro(y_true: np.ndarray, y_prob: np.ndarray, num_thresholds: int = 101) -> float:\n",
        "    \"\"\"\n",
        "    简易版 micro-AP(AUCPR)：在 0~1 阈值上扫一遍，近似计算 PR 曲线下面积\n",
        "    \"\"\"\n",
        "    thresholds = np.linspace(0.0, 1.0, num_thresholds)\n",
        "    precision, recall = [], []\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(np.float32)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "        p = tp / (tp + fp + 1e-9)\n",
        "        r = tp / (tp + fn + 1e-9)\n",
        "        precision.append(p); recall.append(r)\n",
        "    # 按 recall 升序进行梯形积分\n",
        "    order = np.argsort(recall)\n",
        "    recall = np.array(recall)[order]\n",
        "    precision = np.array(precision)[order]\n",
        "    auc_pr = np.trapz(precision, recall)\n",
        "    return float(auc_pr)\n",
        "\n",
        "# ====== 训练/验证循环 =====================================================\n",
        "def train_one_epoch(model, loader, optimizer,\n",
        "                    pos_weight: Optional[paddle.Tensor] = None,\n",
        "                    clip_grad_norm: Optional[float] = None,\n",
        "                    device: str = 'gpu' if paddle.is_compiled_with_cuda() else 'cpu'):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_batches = 0\n",
        "    for x, y in loader:\n",
        "        x = x.astype('float32')\n",
        "        y = y.astype('float32')\n",
        "        logits = model(x)\n",
        "        # BCE with logits（支持 pos_weight）\n",
        "        if pos_weight is not None:\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y, pos_weight=pos_weight)\n",
        "        else:\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
        "        loss.backward()\n",
        "        if clip_grad_norm is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm)\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "        total_loss += float(loss)\n",
        "        total_batches += 1\n",
        "    return total_loss / max(1, total_batches)\n",
        "\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, loader, threshold: float = 0.5):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x, y in loader:\n",
        "        x = x.astype('float32'); y = y.astype('float32')\n",
        "        logits = model(x)                    # (B,4)\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, y)\n",
        "        prob = F.sigmoid(logits).numpy()     # (B,4)\n",
        "        ys.append(y.numpy())\n",
        "        ps.append(prob)\n",
        "        total_loss += float(loss)\n",
        "        total_batches += 1\n",
        "    y_true = np.concatenate(ys, axis=0)\n",
        "    y_prob = np.concatenate(ps, axis=0)\n",
        "    y_pred = (y_prob >= threshold).astype(np.float32)\n",
        "\n",
        "    per_f1, macro_f1, micro_f1 = f1_per_class(y_true, y_pred)\n",
        "    ap_micro = average_precision_micro(y_true, y_prob)\n",
        "    avg_loss = total_loss / max(1, total_batches)\n",
        "    metrics = {\n",
        "        \"loss\": avg_loss,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"per_class_f1\": per_f1.tolist(),\n",
        "        \"micro_AP\": ap_micro\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# ====== 主函数：跑通一个最小示例 ===========================================\n",
        "if __name__ == \"__main__\":\n",
        "    paddle.seed(2025)\n",
        "    # 配置\n",
        "    D = 30              # 数值特征维度\n",
        "    C = 4               # 多标签数\n",
        "    N_train, N_val = 5000, 1000\n",
        "    batch_size = 128\n",
        "    epochs = 5\n",
        "    lr = 3e-4\n",
        "\n",
        "    # 数据\n",
        "    train_ds = ToyMultiLabelDataset(N_train, D, seed=42)\n",
        "    val_ds   = ToyMultiLabelDataset(N_val,   D, seed=233)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    # 类别不平衡（可选）：按训练集估计每个标签的正例比例，构造 pos_weight\n",
        "    y_train = np.vstack([y for _, y in train_ds])\n",
        "    pos_ratio = np.clip(y_train.mean(axis=0), 1e-3, 1-1e-3)   # (4,)\n",
        "    # 经典做法：pos_weight = (N_neg / N_pos) = (1-p)/p\n",
        "    pos_weight_np = (1.0 - pos_ratio) / pos_ratio\n",
        "    pos_weight = paddle.to_tensor(pos_weight_np.astype('float32'))  # (4,)\n",
        "\n",
        "    # 模型\n",
        "    backbone_cfg = dict(n_blocks=3, d_hidden=512, dropout=0.1)\n",
        "    model = MultiLabelClassifier(num_features=D, num_labels=C,\n",
        "                                 arch_type='tabm', k=16,\n",
        "                                 backbone_cfg=backbone_cfg)\n",
        "\n",
        "    optimizer = paddle.optimizer.Adam(learning_rate=lr, parameters=model.parameters())\n",
        "\n",
        "    # 训练\n",
        "    best_macro_f1, best_state = -1.0, None\n",
        "    for ep in range(1, epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer,\n",
        "                                     pos_weight=pos_weight, clip_grad_norm=1.0)\n",
        "        val_metrics = evaluate(model, val_loader, threshold=0.5)\n",
        "        print(f\"[Epoch {ep:02d}] train_loss={train_loss:.4f} | \"\n",
        "              f\"val_loss={val_metrics['loss']:.4f} | \"\n",
        "              f\"macro_f1={val_metrics['macro_f1']:.4f} | \"\n",
        "              f\"micro_f1={val_metrics['micro_f1']:.4f} | \"\n",
        "              f\"per_class_f1={val_metrics['per_class_f1']} | \"\n",
        "              f\"micro_AP={val_metrics['micro_AP']:.4f}\")\n",
        "        # 记录最佳\n",
        "        if val_metrics[\"macro_f1\"] > best_macro_f1:\n",
        "            best_macro_f1 = val_metrics[\"macro_f1\"]\n",
        "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.set_state_dict(best_state)\n",
        "        print(f\"Loaded best state with macro_f1={best_macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOJBZjSyGpSA",
        "outputId": "c23c05d7-0f63-406f-fbcc-66ea0c3065fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1539235308.py:108: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  auc_pr = np.trapz(precision, recall)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] train_loss=0.4427 | val_loss=1.5854 | macro_f1=0.4728 | micro_f1=0.4734 | per_class_f1=[0.5263158082962036, 0.5373737215995789, 0.4471057951450348, 0.38046795129776] | micro_AP=0.4584\n",
            "[Epoch 02] train_loss=0.1538 | val_loss=2.9504 | macro_f1=0.4818 | micro_f1=0.4837 | per_class_f1=[0.553903341293335, 0.5406504273414612, 0.44742268323898315, 0.38532111048698425] | micro_AP=0.4769\n",
            "[Epoch 03] train_loss=0.1057 | val_loss=3.7486 | macro_f1=0.4919 | micro_f1=0.4941 | per_class_f1=[0.5516605377197266, 0.568965494632721, 0.4606299102306366, 0.38624873757362366] | micro_AP=0.4722\n",
            "[Epoch 04] train_loss=0.0917 | val_loss=4.2100 | macro_f1=0.4762 | micro_f1=0.4774 | per_class_f1=[0.5183752179145813, 0.557729959487915, 0.43551796674728394, 0.3932472765445709] | micro_AP=0.4652\n",
            "[Epoch 05] train_loss=0.0732 | val_loss=4.7243 | macro_f1=0.4810 | micro_f1=0.4820 | per_class_f1=[0.5422138571739197, 0.5443425178527832, 0.4589178264141083, 0.3785425126552582] | micro_AP=0.4507\n",
            "Loaded best state with macro_f1=0.4919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import math\n",
        "from typing import Optional, Literal, Tuple\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "from paddle.io import Dataset, DataLoader\n",
        "from paddle.vision.models import resnet18\n",
        "\n",
        "# ====================== 工具：正弦位置编码 ======================\n",
        "class SinusoidalPositionalEncoding(nn.Layer):\n",
        "    def __init__(self, d_model: int, max_len: int = 2048):\n",
        "        super().__init__()\n",
        "        pe = np.zeros((max_len, d_model), dtype=\"float32\")\n",
        "        position = np.arange(0, max_len, dtype=\"float32\")[:, None]\n",
        "        div_term = np.exp(np.arange(0, d_model, 2, dtype=\"float32\") * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = np.sin(position * div_term)\n",
        "        pe[:, 1::2] = np.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", paddle.to_tensor(pe), persistable=False)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        T = x.shape[1]\n",
        "        return x + self.pe[:T, :]\n",
        "\n",
        "# ====================== 简化版 TabM（占位，可换成你的实现） ======================\n",
        "class TabMFeatureExtractor(nn.Layer):\n",
        "    \"\"\"占位实现：MLP → (B, H)。可直接替换为你修好的 TabM。\"\"\"\n",
        "    def __init__(self, num_features: int, d_hidden: int = 512, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(num_features, d_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.d_hidden = d_hidden\n",
        "\n",
        "    def forward(self, x_num: paddle.Tensor):  # (B, 424)\n",
        "        return self.net(x_num)                # (B, H)\n",
        "\n",
        "# ====================== ResNet18 特征抽取（逐帧） ======================\n",
        "class ResNet18FrameEncoder(nn.Layer):\n",
        "    \"\"\"将 ResNet18 改为 20 通道输入；输出每帧 512 维特征。\"\"\"\n",
        "    def __init__(self, in_channels: int = 20):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(pretrained=False)\n",
        "        # 改首层卷积为 20 通道\n",
        "        self.backbone.conv1 = nn.Conv2D(in_channels, 64, kernel_size=7, stride=2, padding=3, bias_attr=False)\n",
        "        # 去掉分类头 fc，保留到 avgpool\n",
        "        self.avgpool = self.backbone.avgpool  # AdaptiveAvgPool2D(1)\n",
        "        # 记录下游维度\n",
        "        self.out_dim = 512\n",
        "\n",
        "    def forward(self, x):  # x: (B*T, C=20, H=20, W=20)\n",
        "        m = self.backbone\n",
        "        x = m.conv1(x); x = m.bn1(x); x = F.relu(x); x = m.maxpool(x)\n",
        "        x = m.layer1(x); x = m.layer2(x); x = m.layer3(x); x = m.layer4(x)\n",
        "        x = self.avgpool(x)          # (B*T, 512, 1, 1)\n",
        "        x = paddle.flatten(x, 1)     # (B*T, 512)\n",
        "        return x\n",
        "\n",
        "# ====================== 时序 Transformer 编码器 ======================\n",
        "class TemporalTransformer(nn.Layer):\n",
        "    def __init__(self, d_model=512, nhead=8, num_layers=4, dim_feedforward=1024, dropout=0.1, max_len=1024):\n",
        "        super().__init__()\n",
        "        enc_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead,\n",
        "                                               dim_feedforward=dim_feedforward,\n",
        "                                               dropout=dropout, activation='relu')\n",
        "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
        "        self.pos = SinusoidalPositionalEncoding(d_model, max_len=max_len)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        x = self.pos(x)\n",
        "        # Paddle 的 Transformer 期望 (T, B, D)\n",
        "        x = paddle.transpose(x, [1, 0, 2])         # (T,B,D)\n",
        "        z = self.encoder(x)                        # (T,B,D)\n",
        "        z = paddle.transpose(z, [1, 0, 2])         # (B,T,D)\n",
        "        return z\n",
        "\n",
        "# ====================== 多头注意力（支持 q from A, kv from B） ======================\n",
        "class MultiHeadCrossAttention(nn.Layer):\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_head = d_model // nhead\n",
        "        self.Wq = nn.Linear(d_model, d_model)\n",
        "        self.Wk = nn.Linear(d_model, d_model)\n",
        "        self.Wv = nn.Linear(d_model, d_model)\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, q, kv):\n",
        "        \"\"\"\n",
        "        q:  (B, Nq, D)\n",
        "        kv: (B, Nk, D)\n",
        "        return: (B, Nq, D)   # 残差 + LN\n",
        "        \"\"\"\n",
        "        B, Nq, D = q.shape\n",
        "        Nk = kv.shape[1]\n",
        "\n",
        "        q_lin = self.Wq(q)  # (B,Nq,D)\n",
        "        k_lin = self.Wk(kv) # (B,Nk,D)\n",
        "        v_lin = self.Wv(kv) # (B,Nk,D)\n",
        "\n",
        "        def split_heads(t):  # (B,N,Heads,dh)\n",
        "            return t.reshape([B, -1, self.nhead, self.d_head]).transpose([0, 2, 1, 3])\n",
        "\n",
        "        qh = split_heads(q_lin)  # (B,H,Nq,dh)\n",
        "        kh = split_heads(k_lin)  # (B,H,Nk,dh)\n",
        "        vh = split_heads(v_lin)  # (B,H,Nk,dh)\n",
        "\n",
        "        scores = paddle.matmul(qh, kh, transpose_y=True) / math.sqrt(self.d_head)  # (B,H,Nq,Nk)\n",
        "        attn = F.softmax(scores, axis=-1)\n",
        "        ctx = paddle.matmul(attn, vh)  # (B,H,Nq,dh)\n",
        "\n",
        "        ctx = ctx.transpose([0, 2, 1, 3]).reshape([B, Nq, D])  # (B,Nq,D)\n",
        "        out = self.proj(ctx)\n",
        "        out = self.drop(out)\n",
        "        # 残差 + LN\n",
        "        return self.ln(out + q)\n",
        "\n",
        "# ====================== 融合头（双向 Cross-Attn） ======================\n",
        "class BiModalCrossFusion(nn.Layer):\n",
        "    \"\"\"\n",
        "    输入：\n",
        "      video_seq: (B, T, D) —— Transformer 后的视频序列\n",
        "      tabm_tok:  (B, D)    —— TabM token\n",
        "    过程：\n",
        "      v_token = mean(video_seq)\n",
        "      v' = CrossAttn(q=v_token[1], kv=tabm_token[1])\n",
        "      t' = CrossAttn(q=tabm_token[1], kv=video_seq[T])\n",
        "      fuse = concat([v', t']) → MLP\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model=512, nhead=8, dropout=0.1, fuse_hidden=512):\n",
        "        super().__init__()\n",
        "        self.ca_v_from_t = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.ca_t_from_v = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(2 * d_model, fuse_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.out_dim = fuse_hidden\n",
        "\n",
        "    def forward(self, video_seq, tabm_tok):\n",
        "        B, T, D = video_seq.shape\n",
        "        # 池化出视频 token\n",
        "        v_tok = video_seq.mean(axis=1, keepdim=True)      # (B,1,D)\n",
        "        t_tok = tabm_tok.unsqueeze(1)                     # (B,1,D)\n",
        "\n",
        "        v_upd = self.ca_v_from_t(v_tok, t_tok)            # (B,1,D)\n",
        "        t_upd = self.ca_t_from_v(t_tok, video_seq)        # (B,1,D)\n",
        "\n",
        "        fused = paddle.concat([v_upd, t_upd], axis=-1)    # (B,1,2D)\n",
        "        fused = fused.squeeze(1)                          # (B,2D)\n",
        "        return self.fuse(fused)                           # (B, F)\n",
        "\n",
        "# ====================== 总模型 ======================\n",
        "class TwoModalMultiLabelModel(nn.Layer):\n",
        "    def __init__(self,\n",
        "                 # 视频模态\n",
        "                 vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "                 # 结构化模态\n",
        "                 vec_dim=424,\n",
        "                 # 维度与结构\n",
        "                 d_model=512, nhead=8, n_trans_layers=4, trans_ff=1024,\n",
        "                 tabm_hidden=512, dropout=0.1, num_labels=4):\n",
        "        super().__init__()\n",
        "        # A: 逐帧 ResNet18\n",
        "        self.frame_encoder = ResNet18FrameEncoder(in_channels=vid_channels)  # (B*T,512)\n",
        "        # A: 时序 Transformer\n",
        "        self.temporal = TemporalTransformer(d_model=d_model,\n",
        "                                            nhead=nhead,\n",
        "                                            num_layers=n_trans_layers,\n",
        "                                            dim_feedforward=trans_ff,\n",
        "                                            dropout=dropout,\n",
        "                                            max_len=vid_frames)\n",
        "        # B: TabM（或替换为你的 TabM）\n",
        "        self.tabm = TabMFeatureExtractor(vec_dim, d_hidden=tabm_hidden, dropout=dropout)\n",
        "        self.tabm_proj = nn.Linear(tabm_hidden, d_model)  # 对齐到 d_model\n",
        "        # 融合：双向 Cross-Attention\n",
        "        self.fusion = BiModalCrossFusion(d_model=d_model, nhead=nhead, dropout=dropout, fuse_hidden=d_model)\n",
        "        # 分类头\n",
        "        self.head = nn.Linear(self.fusion.out_dim, num_labels)\n",
        "\n",
        "    def forward(self, x_video, x_vec):\n",
        "        \"\"\"\n",
        "        x_video: (B, T, C=20, H=20, W=20)\n",
        "        x_vec:   (B, 424)\n",
        "        \"\"\"\n",
        "        B, T, C, H, W = x_video.shape\n",
        "        # ---- A: 逐帧 ResNet ----\n",
        "        xvt = x_video.reshape([B * T, C, H, W])          # (B*T, C, H, W)\n",
        "        f_frame = self.frame_encoder(xvt)                # (B*T, 512)\n",
        "        f_seq = f_frame.reshape([B, T, -1])              # (B, T, 512)\n",
        "        # ---- A: 时序 Transformer ----\n",
        "        z_vid = self.temporal(f_seq)                     # (B, T, 512)\n",
        "        # ---- B: TabM 特征 ----\n",
        "        z_tabm = self.tabm(x_vec)                        # (B, H_tabm)\n",
        "        z_tabm = self.tabm_proj(z_tabm)                  # (B, 512)\n",
        "        # ---- Cross-Attention 融合 ----\n",
        "        fused = self.fusion(z_vid, z_tabm)               # (B, 512)\n",
        "        # ---- 分类 ----\n",
        "        logits = self.head(fused)                        # (B, 4)\n",
        "        return logits\n",
        "\n",
        "# ====================== 指标与训练循环（与前一致） ======================\n",
        "def f1_per_class(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-9) -> Tuple[np.ndarray, float, float]:\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    N, C = y_true.shape\n",
        "    f1_c = np.zeros(C, dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        yt, yp = y_true[:, c], y_pred[:, c]\n",
        "        tp = np.sum((yt == 1) & (yp == 1))\n",
        "        fp = np.sum((yt == 0) & (yp == 1))\n",
        "        fn = np.sum((yt == 1) & (yp == 0))\n",
        "        prec = tp / (tp + fp + eps)\n",
        "        rec  = tp / (tp + fn + eps)\n",
        "        f1_c[c] = 2 * prec * rec / (prec + rec + eps)\n",
        "    macro_f1 = float(np.mean(f1_c))\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    prec = tp / (tp + fp + 1e-9)\n",
        "    rec  = tp / (tp + fn + 1e-9)\n",
        "    micro_f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "    return f1_c, macro_f1, float(micro_f1)\n",
        "\n",
        "def average_precision_micro(y_true: np.ndarray, y_prob: np.ndarray, num_thresholds: int = 101) -> float:\n",
        "    thresholds = np.linspace(0.0, 1.0, num_thresholds)\n",
        "    precision, recall = [], []\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(np.float32)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "        p = tp / (tp + fp + 1e-9)\n",
        "        r = tp / (tp + fn + 1e-9)\n",
        "        precision.append(p); recall.append(r)\n",
        "    order = np.argsort(recall)\n",
        "    recall = np.array(recall)[order]\n",
        "    precision = np.array(precision)[order]\n",
        "    return float(np.trapz(precision, recall))\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer,\n",
        "                    pos_weight: Optional[paddle.Tensor] = None,\n",
        "                    clip_grad_norm: Optional[float] = None):\n",
        "    model.train()\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits = model(x_vid.astype('float32'), x_vec.astype('float32'))\n",
        "        if pos_weight is not None:\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y.astype('float32'), pos_weight=pos_weight)\n",
        "        else:\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, y.astype('float32'))\n",
        "        loss.backward()\n",
        "        if clip_grad_norm is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm)\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "    return total_loss / max(1, total_batches)\n",
        "\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, loader, threshold: float = 0.5):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits = model(x_vid.astype('float32'), x_vec.astype('float32'))\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, y.astype('float32'))\n",
        "        prob = F.sigmoid(logits).numpy()\n",
        "        ys.append(y.numpy()); ps.append(prob)\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "    y_true = np.concatenate(ys, axis=0)\n",
        "    y_prob = np.concatenate(ps, axis=0)\n",
        "    y_pred = (y_prob >= threshold).astype(np.float32)\n",
        "    per_f1, macro_f1, micro_f1 = f1_per_class(y_true, y_pred)\n",
        "    ap_micro = average_precision_micro(y_true, y_prob)\n",
        "    return {\n",
        "        \"loss\": total_loss / max(1, total_batches),\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"per_class_f1\": per_f1.tolist(),\n",
        "        \"micro_AP\": ap_micro\n",
        "    }\n",
        "\n",
        "# ====================== 合成数据集（可替换为真实数据） ======================\n",
        "class ToyTwoModalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    返回：\n",
        "      x_video: (T=365, C=20, H=20, W=20)\n",
        "      x_vec:   (424,)\n",
        "      y:       (4,)  0/1\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, seed: int = 0):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.n = n\n",
        "        # 按 (n, T, C, H, W)\n",
        "        self.video = rng.normal(size=(n, 36, 20, 20, 20)).astype('float32')\n",
        "        self.vec   = rng.normal(size=(n, 424)).astype('float32')\n",
        "\n",
        "        # 造标签：对视频先在 H/W 上均值，再在 T 上均值 → (n, C=20)\n",
        "        vid_hw  = self.video.mean(axis=(3, 4))   # (n, T, C)\n",
        "        vid_avg = vid_hw.mean(axis=1)            # (n, C)\n",
        "\n",
        "        # 线性映射到 4 个标签\n",
        "        Wv = rng.normal(size=(20, 4))            # C→4\n",
        "        Wt = rng.normal(size=(424, 4))           # 424→4\n",
        "        logits = vid_avg @ Wv + self.vec @ Wt + rng.normal(scale=0.5, size=(n, 4))\n",
        "        probs  = 1.0 / (1.0 + np.exp(-logits))\n",
        "        self.y = (probs > 0.5).astype('float32')\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        x_vid = self.video[idx]  # (T,C,H,W)\n",
        "        x_vec = self.vec[idx]    # (424,)\n",
        "        y     = self.y[idx]      # (4,)\n",
        "        return x_vid, x_vec, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "# ====================== 训练入口（可直接运行） ======================\n",
        "if __name__ == \"__main__\":\n",
        "    paddle.seed(2025)\n",
        "    # 数据\n",
        "    train_ds = ToyTwoModalDataset(n=64,  seed=42)   # 注意：真实训练建议更大数据与多卡\n",
        "    val_ds   = ToyTwoModalDataset(n=32,  seed=233)\n",
        "    # 自定义 collate：让视频变成 (B,T,C,H,W)\n",
        "    def collate_fn(batch):\n",
        "        vids, vecs, ys = zip(*batch)\n",
        "        return (paddle.to_tensor(np.stack(vids, 0)),   # (B,T,C,H,W)\n",
        "                paddle.to_tensor(np.stack(vecs, 0)),   # (B,424)\n",
        "                paddle.to_tensor(np.stack(ys, 0)))     # (B,4)\n",
        "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=2, shuffle=False, drop_last=False, collate_fn=collate_fn)\n",
        "\n",
        "    # 类别不平衡权重（可选）\n",
        "    y_train = np.stack([y for _, _, y in train_ds], 0)\n",
        "    pos_ratio = np.clip(y_train.mean(axis=0), 1e-3, 1-1e-3)\n",
        "    pos_weight = paddle.to_tensor(((1-pos_ratio)/pos_ratio).astype('float32'))  # (4,)\n",
        "\n",
        "    # 模型\n",
        "    model = TwoModalMultiLabelModel(\n",
        "        vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "        vec_dim=424,\n",
        "        d_model=512, nhead=2, n_trans_layers=2, trans_ff=1024,  # 可调\n",
        "        tabm_hidden=512, dropout=0.1,\n",
        "        num_labels=4\n",
        "    )\n",
        "    optimizer = paddle.optimizer.Adam(learning_rate=3e-4, parameters=model.parameters())\n",
        "\n",
        "    # 训练（演示用：小 epoch）\n",
        "    best_macro_f1, best = -1.0, None\n",
        "    for ep in range(1, 3+1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer,\n",
        "                                     pos_weight=pos_weight, clip_grad_norm=1.0)\n",
        "        val_metrics = evaluate(model, val_loader, threshold=0.5)\n",
        "        print(f\"[Epoch {ep:02d}] train_loss={train_loss:.4f} | \"\n",
        "              f\"val_loss={val_metrics['loss']:.4f} | \"\n",
        "              f\"macro_f1={val_metrics['macro_f1']:.4f} | \"\n",
        "              f\"micro_f1={val_metrics['micro_f1']:.4f} | \"\n",
        "              f\"per_class_f1={val_metrics['per_class_f1']} | \"\n",
        "              f\"micro_AP={val_metrics['micro_AP']:.4f}\")\n",
        "        if val_metrics[\"macro_f1\"] > best_macro_f1:\n",
        "            best_macro_f1 = val_metrics[\"macro_f1\"]\n",
        "            best = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best is not None:\n",
        "        model.set_state_dict(best)\n",
        "        print(f\"Loaded best state with macro_f1={best_macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7-O1-LZLHB2",
        "outputId": "124d09eb-3e79-4622-f0b3-b2bf7eb11d60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3157620546.py:248: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(precision, recall))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] train_loss=1.1304 | val_loss=1.0465 | macro_f1=0.3765 | micro_f1=0.5079 | per_class_f1=[0.5, 0.7450980544090271, 0.260869562625885, 0.0] | micro_AP=0.5393\n",
            "[Epoch 02] train_loss=0.7661 | val_loss=0.9369 | macro_f1=0.5812 | micro_f1=0.6173 | per_class_f1=[0.5454545617103577, 0.7599999904632568, 0.6382978558540344, 0.380952388048172] | micro_AP=0.4165\n",
            "[Epoch 03] train_loss=0.4050 | val_loss=1.9395 | macro_f1=0.6107 | micro_f1=0.6303 | per_class_f1=[0.5454545617103577, 0.7234042286872864, 0.6938775777816772, 0.47999998927116394] | micro_AP=0.3836\n",
            "Loaded best state with macro_f1=0.6107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "from paddle.io import Dataset, DataLoader\n",
        "from paddle.vision.models import resnet18\n",
        "\n",
        "# ====================== 工具：正弦位置编码 ======================\n",
        "class SinusoidalPositionalEncoding(nn.Layer):\n",
        "    def __init__(self, d_model: int, max_len: int = 2048):\n",
        "        super().__init__()\n",
        "        pe = np.zeros((max_len, d_model), dtype=\"float32\")\n",
        "        position = np.arange(0, max_len, dtype=\"float32\")[:, None]\n",
        "        div_term = np.exp(np.arange(0, d_model, 2, dtype=\"float32\") * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = np.sin(position * div_term)\n",
        "        pe[:, 1::2] = np.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", paddle.to_tensor(pe), persistable=False)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        T = x.shape[1]\n",
        "        return x + self.pe[:T, :]\n",
        "\n",
        "# ====================== 简化版 TabM（占位，可换成你的实现） ======================\n",
        "class TabMFeatureExtractor(nn.Layer):\n",
        "    \"\"\"占位实现：MLP → (B, H)。可直接替换为你修好的 TabM。\"\"\"\n",
        "    def __init__(self, num_features: int, d_hidden: int = 512, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(num_features, d_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.d_hidden = d_hidden\n",
        "\n",
        "    def forward(self, x_num: paddle.Tensor):  # (B, 424)\n",
        "        return self.net(x_num)                # (B, H)\n",
        "\n",
        "# ====================== ResNet18 特征抽取（逐帧） ======================\n",
        "class ResNet18FrameEncoder(nn.Layer):\n",
        "    \"\"\"将 ResNet18 改为 20 通道输入；输出每帧 512 维特征。\"\"\"\n",
        "    def __init__(self, in_channels: int = 20):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(pretrained=False)\n",
        "        # 改首层卷积为 20 通道\n",
        "        self.backbone.conv1 = nn.Conv2D(in_channels, 64, kernel_size=7, stride=2, padding=3, bias_attr=False)\n",
        "        # 去掉分类头 fc，保留到 avgpool\n",
        "        self.avgpool = self.backbone.avgpool  # AdaptiveAvgPool2D(1)\n",
        "        self.out_dim = 512\n",
        "\n",
        "    def forward(self, x):  # x: (B*T, C=20, H=20, W=20)\n",
        "        m = self.backbone\n",
        "        x = m.conv1(x); x = m.bn1(x); x = F.relu(x); x = m.maxpool(x)\n",
        "        x = m.layer1(x); x = m.layer2(x); x = m.layer3(x); x = m.layer4(x)\n",
        "        x = self.avgpool(x)          # (B*T, 512, 1, 1)\n",
        "        x = paddle.flatten(x, 1)     # (B*T, 512)\n",
        "        return x\n",
        "\n",
        "# ====================== MoE 基础实现（Top-k，可开关；使用 gather_nd 修复） ======================\n",
        "class ExpertFFN(nn.Layer):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1, act='relu'):\n",
        "        super().__init__()\n",
        "        Act = getattr(F, act) if isinstance(act, str) else act\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.act = Act\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.drop(self.act(self.fc1(x))))\n",
        "\n",
        "class MoEConfig:\n",
        "    def __init__(self,\n",
        "                 n_experts=8,\n",
        "                 top_k=1,\n",
        "                 d_ff=2048,\n",
        "                 dropout=0.1,\n",
        "                 router_temp=0.5,\n",
        "                 balance_loss_w=0.005,\n",
        "                 entropy_reg_w=-0.005,  # 负值→更尖锐\n",
        "                 diversity_w=1e-3,\n",
        "                 sticky_w=0.0,\n",
        "                 sup_router_w=0.0,\n",
        "                 use_gumbel=True):\n",
        "        self.n_experts = n_experts\n",
        "        self.top_k = top_k\n",
        "        self.d_ff = d_ff\n",
        "        self.dropout = dropout\n",
        "        self.router_temp = router_temp\n",
        "        self.balance_loss_w = balance_loss_w\n",
        "        self.entropy_reg_w = entropy_reg_w\n",
        "        self.diversity_w = diversity_w\n",
        "        self.sticky_w = sticky_w\n",
        "        self.sup_router_w = sup_router_w\n",
        "        self.use_gumbel = use_gumbel\n",
        "\n",
        "class MoE(nn.Layer):\n",
        "    \"\"\"forward(x, domain_id=None) → (y, aux_loss)，支持 (B,T,D) 或 (N,D)\"\"\"\n",
        "    def __init__(self, d_model: int, cfg: MoEConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.router = nn.Linear(d_model, cfg.n_experts)\n",
        "        self.experts = nn.LayerList([ExpertFFN(d_model, cfg.d_ff, cfg.dropout) for _ in range(cfg.n_experts)])\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(cfg.dropout)\n",
        "\n",
        "    def _router_probs(self, logits):\n",
        "        if self.cfg.use_gumbel and self.training:\n",
        "            u = paddle.uniform(logits.shape, min=1e-6, max=1-1e-6, dtype=logits.dtype)\n",
        "            g = -paddle.log(-paddle.log(u))\n",
        "            logits = logits + g\n",
        "        return F.softmax(logits / self.cfg.router_temp, axis=-1)\n",
        "\n",
        "    def forward(self, x, domain_id=None):\n",
        "        orig_shape = x.shape\n",
        "        if len(orig_shape) == 3:\n",
        "            B, T, D = orig_shape\n",
        "            X = x.reshape([B*T, D])\n",
        "        else:\n",
        "            X = x\n",
        "        N, D = X.shape\n",
        "\n",
        "        logits = self.router(X)             # (N,E)\n",
        "        probs = self._router_probs(logits)  # (N,E)\n",
        "        topk_val, topk_idx = paddle.topk(probs, k=self.cfg.top_k, axis=-1)  # (N,k)\n",
        "\n",
        "        # 专家并行输出\n",
        "        all_out = paddle.stack([e(X) for e in self.experts], axis=1)         # (N,E,D)\n",
        "\n",
        "        # === 使用 gather_nd 逐样本选择 top-k 专家 ===\n",
        "        arangeN = paddle.arange(N, dtype='int64')\n",
        "        picked_list = []\n",
        "        for i in range(self.cfg.top_k):\n",
        "            idx_i = topk_idx[:, i].astype('int64')                   # (N,)\n",
        "            idx_nd = paddle.stack([arangeN, idx_i], axis=1)          # (N,2) [sample, expert]\n",
        "            picked_i = paddle.gather_nd(all_out, idx_nd)             # (N,D)\n",
        "            picked_list.append(picked_i)\n",
        "        picked = paddle.stack(picked_list, axis=1)                   # (N,k,D)\n",
        "\n",
        "        # 归一化权重并加权\n",
        "        w = topk_val / (paddle.sum(topk_val, axis=-1, keepdim=True) + 1e-9)  # (N,k)\n",
        "        Y = paddle.sum(picked * w.unsqueeze(-1), axis=1)                      # (N,D)\n",
        "\n",
        "        Y = self.drop(Y)\n",
        "        Y = self.ln(Y + X)\n",
        "\n",
        "        # aux loss\n",
        "        aux = 0.0\n",
        "        if self.cfg.balance_loss_w > 0:\n",
        "            mean_prob = probs.mean(axis=0)\n",
        "            target = paddle.full_like(mean_prob, 1.0 / self.cfg.n_experts)\n",
        "            aux = aux + self.cfg.balance_loss_w * F.mse_loss(mean_prob, target)\n",
        "        if self.cfg.entropy_reg_w != 0.0:\n",
        "            ent = -paddle.sum(probs * (paddle.log(probs + 1e-9)), axis=1).mean()\n",
        "            aux = aux + self.cfg.entropy_reg_w * ent\n",
        "        if (domain_id is not None) and (self.cfg.sup_router_w > 0):\n",
        "            dom = domain_id.reshape([-1])[:N] % self.cfg.n_experts\n",
        "            aux = aux + self.cfg.sup_router_w * F.cross_entropy(logits, dom)\n",
        "        if self.cfg.diversity_w > 0 and self.cfg.n_experts > 1:\n",
        "            # 用 top-1 硬选择近似每个专家接收的样本\n",
        "            chosen = F.one_hot(topk_idx[:, 0], num_classes=self.cfg.n_experts).astype('float32')  # (N,E)\n",
        "            denom = chosen.sum(axis=0).clip(min=1.0).unsqueeze(-1)\n",
        "            means = (all_out * chosen.unsqueeze(-1)).sum(axis=0) / denom                           # (E,D)\n",
        "            sims = []\n",
        "            for i in range(self.cfg.n_experts):\n",
        "                for j in range(i+1, self.cfg.n_experts):\n",
        "                    si = F.normalize(means[i:i+1], axis=-1)\n",
        "                    sj = F.normalize(means[j:j+1], axis=-1)\n",
        "                    sims.append((si*sj).sum())\n",
        "            if sims:\n",
        "                aux = aux + self.cfg.diversity_w * paddle.stack(sims).mean()\n",
        "\n",
        "        if len(orig_shape) == 3:\n",
        "            Y = Y.reshape([B, T, D])\n",
        "        return Y, aux\n",
        "\n",
        "class MoEHead(nn.Layer):\n",
        "    \"\"\"单 token MoE 头，用于 fused/tabm 投影后的 (B, D)\"\"\"\n",
        "    def __init__(self, d_model=512, cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.moe = MoE(d_model, cfg or MoEConfig())\n",
        "    def forward(self, tok, domain_id=None):\n",
        "        y, aux = self.moe(tok.unsqueeze(1), domain_id=domain_id)  # (B,1,D)\n",
        "        return y.squeeze(1), aux\n",
        "\n",
        "# ====================== 自定义 Transformer Encoder（FFN 可替换为 MoE） ======================\n",
        "class TransformerEncoderLayerMoE(nn.Layer):\n",
        "    def __init__(self, d_model=512, nhead=8, d_ff=1024, dropout=0.1,\n",
        "                 use_moe: bool = True, moe_cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.use_moe = use_moe\n",
        "        self.self_attn = nn.MultiHeadAttention(embed_dim=d_model, num_heads=nhead, dropout=dropout)\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.do1 = nn.Dropout(dropout)\n",
        "        if use_moe:\n",
        "            self.moe = MoE(d_model, moe_cfg or MoEConfig(d_ff=d_ff, dropout=dropout))\n",
        "        else:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.LayerNorm(d_model),\n",
        "                nn.Linear(d_model, d_ff),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(d_ff, d_model),\n",
        "            )\n",
        "            self.do2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, domain_id=None):  # x: (B,T,D)\n",
        "        # Self-Attention (pre-norm) —— Paddle MHA 期望 (T,B,D)\n",
        "        h = self.ln1(x)\n",
        "        h = paddle.transpose(h, [1, 0, 2])          # (T,B,D)\n",
        "        sa = self.self_attn(h, h, h)                # (T,B,D)\n",
        "        sa = paddle.transpose(sa, [1, 0, 2])        # (B,T,D)\n",
        "        x = x + self.do1(sa)\n",
        "        aux = 0.0\n",
        "        if self.use_moe:\n",
        "            x, aux = self.moe(x, domain_id=domain_id)  # 残差+LN 在 MoE 内部\n",
        "        else:\n",
        "            x = x + self.do2(self.ffn(x))              # 残差在这里\n",
        "        return x, aux\n",
        "\n",
        "class TemporalTransformerFlexible(nn.Layer):\n",
        "    def __init__(self, d_model=512, nhead=8, num_layers=2, d_ff=1024, dropout=0.1,\n",
        "                 max_len=1024, use_moe: bool = True, moe_cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.pos = SinusoidalPositionalEncoding(d_model, max_len=max_len)\n",
        "        self.layers = nn.LayerList([\n",
        "            TransformerEncoderLayerMoE(d_model, nhead, d_ff, dropout,\n",
        "                                       use_moe=use_moe, moe_cfg=moe_cfg)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "    def forward(self, x, domain_id=None):  # x: (B,T,D)\n",
        "        x = self.pos(x)\n",
        "        aux_total = 0.0\n",
        "        for layer in self.layers:\n",
        "            x, aux = layer(x, domain_id=domain_id)\n",
        "            aux_total = aux_total + aux\n",
        "        return x, aux_total\n",
        "\n",
        "# ====================== 多头注意力（支持 q from A, kv from B） ======================\n",
        "class MultiHeadCrossAttention(nn.Layer):\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_head = d_model // nhead\n",
        "        self.Wq = nn.Linear(d_model, d_model)\n",
        "        self.Wk = nn.Linear(d_model, d_model)\n",
        "        self.Wv = nn.Linear(d_model, d_model)\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, q, kv):\n",
        "        B, Nq, D = q.shape\n",
        "        Nk = kv.shape[1]\n",
        "        q_lin = self.Wq(q); k_lin = self.Wk(kv); v_lin = self.Wv(kv)\n",
        "        def split_heads(t):\n",
        "            return t.reshape([B, -1, self.nhead, self.d_head]).transpose([0, 2, 1, 3])\n",
        "        qh = split_heads(q_lin); kh = split_heads(k_lin); vh = split_heads(v_lin)\n",
        "        scores = paddle.matmul(qh, kh, transpose_y=True) / math.sqrt(self.d_head)\n",
        "        attn = F.softmax(scores, axis=-1)\n",
        "        ctx = paddle.matmul(attn, vh)\n",
        "        ctx = ctx.transpose([0, 2, 1, 3]).reshape([B, Nq, D])\n",
        "        out = self.proj(ctx)\n",
        "        out = self.drop(out)\n",
        "        return self.ln(out + q)\n",
        "\n",
        "# ====================== 融合头（双向 Cross-Attn） ======================\n",
        "class BiModalCrossFusion(nn.Layer):\n",
        "    \"\"\"\n",
        "    输入：\n",
        "      video_seq: (B, T, D) —— Transformer 后的视频序列\n",
        "      tabm_tok:  (B, D)    —— TabM token\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model=512, nhead=8, dropout=0.1, fuse_hidden=512):\n",
        "        super().__init__()\n",
        "        self.ca_v_from_t = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.ca_t_from_v = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(2 * d_model, fuse_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.out_dim = fuse_hidden\n",
        "\n",
        "    def forward(self, video_seq, tabm_tok):\n",
        "        B, T, D = video_seq.shape\n",
        "        # 池化视频时间维得到 token\n",
        "        v_tok = video_seq.mean(axis=1, keepdim=True)      # (B,1,D)\n",
        "        t_tok = tabm_tok.unsqueeze(1)                     # (B,1,D)\n",
        "        v_upd = self.ca_v_from_t(v_tok, t_tok)            # (B,1,D)\n",
        "        t_upd = self.ca_t_from_v(t_tok, video_seq)        # (B,1,D)\n",
        "        fused = paddle.concat([v_upd, t_upd], axis=-1)    # (B,1,2D)\n",
        "        fused = fused.squeeze(1)                          # (B,2D)\n",
        "        return self.fuse(fused)                           # (B, F)\n",
        "\n",
        "# ====================== 总模型（带三个 MoE 开关） ======================\n",
        "class TwoModalMultiLabelModel(nn.Layer):\n",
        "    def __init__(self,\n",
        "                 # 视频模态\n",
        "                 vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "                 # 结构化模态\n",
        "                 vec_dim=424,\n",
        "                 # 维度与结构\n",
        "                 d_model=512, nhead=2, n_trans_layers=2, trans_ff=1024,\n",
        "                 tabm_hidden=512, dropout=0.1, num_labels=4,\n",
        "                 # ===== MoE 开关 =====\n",
        "                 moe_temporal: bool = True,      # 时序 Transformer 的 FFN 位置\n",
        "                 moe_fused: bool = False,        # 融合 token 上的小型 MoE 头\n",
        "                 moe_tabm: bool = False,         # TabM 投影后\n",
        "                 # ===== MoE 超参（可传入自定义） =====\n",
        "                 moe_cfg_temporal: MoEConfig = None,\n",
        "                 moe_cfg_fused: MoEConfig = None,\n",
        "                 moe_cfg_tabm: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        # A: 逐帧 ResNet18\n",
        "        self.frame_encoder = ResNet18FrameEncoder(in_channels=vid_channels)\n",
        "        # A: 时序 Transformer（可开/关 MoE）\n",
        "        self.temporal = TemporalTransformerFlexible(\n",
        "            d_model=d_model, nhead=nhead, num_layers=n_trans_layers,\n",
        "            d_ff=trans_ff, dropout=dropout, max_len=vid_frames,\n",
        "            use_moe=moe_temporal,\n",
        "            moe_cfg=moe_cfg_temporal or MoEConfig(\n",
        "                n_experts=8, top_k=1, d_ff=max(trans_ff, 2048), router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            )\n",
        "        )\n",
        "        # B: TabM（或你的 TabM）\n",
        "        self.tabm = TabMFeatureExtractor(vec_dim, d_hidden=tabm_hidden, dropout=dropout)\n",
        "        self.tabm_proj = nn.Linear(tabm_hidden, d_model)\n",
        "\n",
        "        # 可选：TabM 分支 MoE 头\n",
        "        self.moe_tabm = moe_tabm\n",
        "        if moe_tabm:\n",
        "            self.tabm_moe = MoEHead(d_model=d_model, cfg=moe_cfg_tabm or MoEConfig(\n",
        "                n_experts=6, top_k=1, d_ff=1024, router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            ))\n",
        "\n",
        "        # 融合：双向 Cross-Attention\n",
        "        self.fusion = BiModalCrossFusion(d_model=d_model, nhead=nhead, dropout=dropout, fuse_hidden=d_model)\n",
        "\n",
        "        # 可选：融合 token MoE 头\n",
        "        self.moe_fused = moe_fused\n",
        "        if moe_fused:\n",
        "            self.fused_moe = MoEHead(d_model=d_model, cfg=moe_cfg_fused or MoEConfig(\n",
        "                n_experts=6, top_k=1, d_ff=1024, router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            ))\n",
        "\n",
        "        # 分类头\n",
        "        self.head = nn.Linear(self.fusion.out_dim, num_labels)\n",
        "\n",
        "    def forward(self, x_video, x_vec, domain_id=None):\n",
        "        \"\"\"\n",
        "        x_video: (B, T, C=20, H=20, W=20)\n",
        "        x_vec:   (B, 424)\n",
        "        domain_id: (B,) 或 None —— 若有域/季节/站点标签，可传入以做监督路由（可选）\n",
        "        \"\"\"\n",
        "        B, T, C, H, W = x_video.shape\n",
        "        # ---- A: 逐帧 ResNet ----\n",
        "        xvt = x_video.reshape([B * T, C, H, W])          # (B*T, C, H, W)\n",
        "        f_frame = self.frame_encoder(xvt)                # (B*T, 512)\n",
        "        f_seq = f_frame.reshape([B, T, -1])              # (B, T, 512)\n",
        "        # ---- A: 时序 Transformer (可含 MoE) ----\n",
        "        z_vid, aux_total = self.temporal(f_seq, domain_id=domain_id)   # (B,T,512), aux\n",
        "\n",
        "        # ---- B: TabM 特征 ----\n",
        "        z_tabm = self.tabm(x_vec)                        # (B, H_tabm)\n",
        "        z_tabm = self.tabm_proj(z_tabm)                  # (B, 512)\n",
        "        if self.moe_tabm:\n",
        "            z_tabm, aux_t = self.tabm_moe(z_tabm, domain_id=domain_id)  # (B,512)\n",
        "            aux_total = aux_total + aux_t\n",
        "\n",
        "        # ---- Cross-Attention 融合 ----\n",
        "        fused = self.fusion(z_vid, z_tabm)               # (B, 512)\n",
        "\n",
        "        # ---- 融合 MoE 头（可选） ----\n",
        "        if self.moe_fused:\n",
        "            fused, aux_f = self.fused_moe(fused, domain_id=domain_id)  # (B,512)\n",
        "            aux_total = aux_total + aux_f\n",
        "\n",
        "        # ---- 分类 ----\n",
        "        logits = self.head(fused)                        # (B, 4)\n",
        "        return logits, aux_total\n",
        "\n",
        "# ====================== 指标与训练循环（兼容 aux_loss） ======================\n",
        "def f1_per_class(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-9) -> Tuple[np.ndarray, float, float]:\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    N, C = y_true.shape\n",
        "    f1_c = np.zeros(C, dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        yt, yp = y_true[:, c], y_pred[:, c]\n",
        "        tp = np.sum((yt == 1) & (yp == 1))\n",
        "        fp = np.sum((yt == 0) & (yp == 1))\n",
        "        fn = np.sum((yt == 1) & (yp == 0))\n",
        "        prec = tp / (tp + fp + eps)\n",
        "        rec  = tp / (tp + fn + eps)\n",
        "        f1_c[c] = 2 * prec * rec / (prec + rec + eps)\n",
        "    macro_f1 = float(np.mean(f1_c))\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    prec = tp / (tp + fp + 1e-9)\n",
        "    rec  = tp / (tp + fn + 1e-9)\n",
        "    micro_f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "    return f1_c, macro_f1, float(micro_f1)\n",
        "\n",
        "def average_precision_micro(y_true: np.ndarray, y_prob: np.ndarray, num_thresholds: int = 101) -> float:\n",
        "    thresholds = np.linspace(0.0, 1.0, num_thresholds)\n",
        "    precision, recall = [], []\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(np.float32)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "        p = tp / (tp + fp + 1e-9)\n",
        "        r = tp / (tp + fn + 1e-9)\n",
        "        precision.append(p); recall.append(r)\n",
        "    order = np.argsort(recall)\n",
        "    recall = np.array(recall)[order]\n",
        "    precision = np.array(precision)[order]\n",
        "    return float(np.trapz(precision, recall))\n",
        "\n",
        "LAMBDA_MOE = 0.01  # MoE 辅助损失系数\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer,\n",
        "                    pos_weight: Optional[paddle.Tensor] = None,\n",
        "                    clip_grad_norm: Optional[float] = None):\n",
        "    model.train()\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits, aux = model(x_vid.astype('float32'), x_vec.astype('float32'))  # ← 接收 aux\n",
        "        if pos_weight is not None:\n",
        "            cls = F.binary_cross_entropy_with_logits(logits, y.astype('float32'), pos_weight=pos_weight)\n",
        "        else:\n",
        "            cls = F.binary_cross_entropy_with_logits(logits, y.astype('float32'))\n",
        "        loss = cls + LAMBDA_MOE * aux\n",
        "        loss.backward()\n",
        "        if clip_grad_norm is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm)\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "    return total_loss / max(1, total_batches)\n",
        "\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, loader, threshold: float = 0.5):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits, aux = model(x_vid.astype('float32'), x_vec.astype('float32'))  # ← 接收 aux\n",
        "        cls = F.binary_cross_entropy_with_logits(logits, y.astype('float32'))\n",
        "        loss = cls + LAMBDA_MOE * aux\n",
        "        prob = F.sigmoid(logits).numpy()\n",
        "        ys.append(y.numpy()); ps.append(prob)\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "    y_true = np.concatenate(ys, axis=0)\n",
        "    y_prob = np.concatenate(ps, axis=0)\n",
        "    y_pred = (y_prob >= threshold).astype(np.float32)\n",
        "    per_f1, macro_f1, micro_f1 = f1_per_class(y_true, y_pred)\n",
        "    ap_micro = average_precision_micro(y_true, y_prob)\n",
        "    return {\n",
        "        \"loss\": total_loss / max(1, total_batches),\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"per_class_f1\": per_f1.tolist(),\n",
        "        \"micro_AP\": ap_micro\n",
        "    }\n",
        "\n",
        "# ====================== 合成数据集（可替换为真实数据） ======================\n",
        "class ToyTwoModalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    返回：\n",
        "      x_video: (T=36, C=20, H=20, W=20)\n",
        "      x_vec:   (424,)\n",
        "      y:       (4,)  0/1\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, seed: int = 0):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.n = n\n",
        "        # 按 (n, T, C, H, W)\n",
        "        self.video = rng.normal(size=(n, 36, 20, 20, 20)).astype('float32')\n",
        "        self.vec   = rng.normal(size=(n, 424)).astype('float32')\n",
        "\n",
        "        # 造标签：对视频先在 H/W 上均值，再在 T 上均值 → (n, C=20)\n",
        "        vid_hw  = self.video.mean(axis=(3, 4))   # (n, T, C)\n",
        "        vid_avg = vid_hw.mean(axis=1)            # (n, C)\n",
        "\n",
        "        # 线性映射到 4 个标签\n",
        "        Wv = rng.normal(size=(20, 4))            # C→4\n",
        "        Wt = rng.normal(size=(424, 4))           # 424→4\n",
        "        logits = vid_avg @ Wv + self.vec @ Wt + rng.normal(scale=0.5, size=(n, 4))\n",
        "        probs  = 1.0 / (1.0 + np.exp(-logits))\n",
        "        self.y = (probs > 0.5).astype('float32')\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        x_vid = self.video[idx]  # (T,C,H,W)\n",
        "        x_vec = self.vec[idx]    # (424,)\n",
        "        y     = self.y[idx]      # (4,)\n",
        "        return x_vid, x_vec, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "# ====================== 训练入口（可直接运行） ======================\n",
        "if __name__ == \"__main__\":\n",
        "    paddle.seed(2025)\n",
        "    # 数据\n",
        "    train_ds = ToyTwoModalDataset(n=64,  seed=42)\n",
        "    val_ds   = ToyTwoModalDataset(n=32,  seed=233)\n",
        "    def collate_fn(batch):\n",
        "        vids, vecs, ys = zip(*batch)\n",
        "        return (paddle.to_tensor(np.stack(vids, 0)),   # (B,T,C,H,W)\n",
        "                paddle.to_tensor(np.stack(vecs, 0)),   # (B,424)\n",
        "                paddle.to_tensor(np.stack(ys, 0)))     # (B,4)\n",
        "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=2, shuffle=False, drop_last=False, collate_fn=collate_fn)\n",
        "\n",
        "    # 类别不平衡权重（可选）\n",
        "    y_train = np.stack([y for _, _, y in train_ds], 0)\n",
        "    pos_ratio = np.clip(y_train.mean(axis=0), 1e-3, 1-1e-3)\n",
        "    pos_weight = paddle.to_tensor(((1-pos_ratio)/pos_ratio).astype('float32'))  # (4,)\n",
        "\n",
        "    # === 构建模型：三处 MoE 开关（默认只开时序 MoE） ===\n",
        "    model = TwoModalMultiLabelModel(\n",
        "        vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "        vec_dim=424,\n",
        "        d_model=512, nhead=2, n_trans_layers=2, trans_ff=1024,\n",
        "        tabm_hidden=512, dropout=0.1,\n",
        "        num_labels=4,\n",
        "        moe_temporal=True,     # 开：时序 Transformer 的 FFN 位置\n",
        "        moe_fused=False,       # 关：融合 token MoE 头\n",
        "        moe_tabm=False         # 关：TabM 投影后 MoE\n",
        "    )\n",
        "    optimizer = paddle.optimizer.Adam(learning_rate=3e-4, parameters=model.parameters())\n",
        "\n",
        "    # 训练（演示用：小 epoch）\n",
        "    best_macro_f1, best = -1.0, None\n",
        "    for ep in range(1, 3+1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer,\n",
        "                                     pos_weight=pos_weight, clip_grad_norm=1.0)\n",
        "        val_metrics = evaluate(model, val_loader, threshold=0.5)\n",
        "        print(f\"[Epoch {ep:02d}] train_loss={train_loss:.4f} | \"\n",
        "              f\"val_loss={val_metrics['loss']:.4f} | \"\n",
        "              f\"macro_f1={val_metrics['macro_f1']:.4f} | \"\n",
        "              f\"micro_f1={val_metrics['micro_f1']:.4f} | \"\n",
        "              f\"per_class_f1={val_metrics['per_class_f1']} | \"\n",
        "              f\"micro_AP={val_metrics['micro_AP']:.4f}\")\n",
        "        if val_metrics[\"macro_f1\"] > best_macro_f1:\n",
        "            best_macro_f1 = val_metrics[\"macro_f1\"]\n",
        "            best = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best is not None:\n",
        "        model.set_state_dict(best)\n",
        "        print(f\"Loaded best state with macro_f1={best_macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5On1aO5QtFw",
        "outputId": "aeecef88-dd57-4133-8156-f3dd9b6e0c90"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3896222078.py:427: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(precision, recall))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] train_loss=1.0045 | val_loss=0.8427 | macro_f1=0.1364 | micro_f1=0.2609 | per_class_f1=[0.0, 0.0, 0.0, 0.5454545617103577] | micro_AP=0.4593\n",
            "[Epoch 02] train_loss=0.6558 | val_loss=1.0130 | macro_f1=0.4563 | micro_f1=0.5342 | per_class_f1=[0.5945945978164673, 0.0, 0.6938775777816772, 0.5365853905677795] | micro_AP=0.5376\n",
            "[Epoch 03] train_loss=0.2265 | val_loss=1.3452 | macro_f1=0.4934 | micro_f1=0.5625 | per_class_f1=[0.4000000059604645, 0.7234042286872864, 0.6000000238418579, 0.25] | micro_AP=0.5076\n",
            "Loaded best state with macro_f1=0.4934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "import numpy as np\n",
        "import paddle\n",
        "import paddle.nn as nn\n",
        "import paddle.nn.functional as F\n",
        "from paddle.io import Dataset, DataLoader\n",
        "from paddle.vision.models import resnet18\n",
        "\n",
        "# ====================== 工具：正弦位置编码 ======================\n",
        "class SinusoidalPositionalEncoding(nn.Layer):\n",
        "    def __init__(self, d_model: int, max_len: int = 2048):\n",
        "        super().__init__()\n",
        "        pe = np.zeros((max_len, d_model), dtype=\"float32\")\n",
        "        position = np.arange(0, max_len, dtype=\"float32\")[:, None]\n",
        "        div_term = np.exp(np.arange(0, d_model, 2, dtype=\"float32\") * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = np.sin(position * div_term)\n",
        "        pe[:, 1::2] = np.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", paddle.to_tensor(pe), persistable=False)\n",
        "\n",
        "    def forward(self, x):  # x: (B, T, D)\n",
        "        T = x.shape[1]\n",
        "        return x + self.pe[:T, :]\n",
        "\n",
        "# ====================== 简化版 TabM（占位，可换成你的实现） ======================\n",
        "class TabMFeatureExtractor(nn.Layer):\n",
        "    \"\"\"占位实现：MLP → (B, H)。可直接替换为你修好的 TabM。\"\"\"\n",
        "    def __init__(self, num_features: int, d_hidden: int = 512, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(num_features, d_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.d_hidden = d_hidden\n",
        "\n",
        "    def forward(self, x_num: paddle.Tensor):  # (B, 424)\n",
        "        return self.net(x_num)                # (B, H)\n",
        "\n",
        "# ====================== ResNet18 特征抽取（逐帧） ======================\n",
        "class ResNet18FrameEncoder(nn.Layer):\n",
        "    \"\"\"将 ResNet18 改为 20 通道输入；输出每帧 512 维特征。\"\"\"\n",
        "    def __init__(self, in_channels: int = 20):\n",
        "        super().__init__()\n",
        "        self.backbone = resnet18(pretrained=False)\n",
        "        # 改首层卷积为 20 通道\n",
        "        self.backbone.conv1 = nn.Conv2D(in_channels, 64, kernel_size=7, stride=2, padding=3, bias_attr=False)\n",
        "        # 去掉分类头 fc，保留到 avgpool\n",
        "        self.avgpool = self.backbone.avgpool  # AdaptiveAvgPool2D(1)\n",
        "        self.out_dim = 512\n",
        "\n",
        "    def forward(self, x):  # x: (B*T, C=20, H=20, W=20)\n",
        "        m = self.backbone\n",
        "        x = m.conv1(x); x = m.bn1(x); x = F.relu(x); x = m.maxpool(x)\n",
        "        x = m.layer1(x); x = m.layer2(x); x = m.layer3(x); x = m.layer4(x)\n",
        "        x = self.avgpool(x)          # (B*T, 512, 1, 1)\n",
        "        x = paddle.flatten(x, 1)     # (B*T, 512)\n",
        "        return x\n",
        "\n",
        "# ====================== MoE 基础实现（Top-k，可开关；使用 gather_nd 修复） ======================\n",
        "class ExpertFFN(nn.Layer):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1, act='relu'):\n",
        "        super().__init__()\n",
        "        Act = getattr(F, act) if isinstance(act, str) else act\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.act = Act\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.drop(self.act(self.fc1(x))))\n",
        "\n",
        "class MoEConfig:\n",
        "    def __init__(self,\n",
        "                 n_experts=8,\n",
        "                 top_k=1,\n",
        "                 d_ff=2048,\n",
        "                 dropout=0.1,\n",
        "                 router_temp=0.5,\n",
        "                 balance_loss_w=0.005,\n",
        "                 entropy_reg_w=-0.005,  # 负值→更尖锐\n",
        "                 diversity_w=1e-3,\n",
        "                 sticky_w=0.0,\n",
        "                 sup_router_w=0.0,\n",
        "                 use_gumbel=True):\n",
        "        self.n_experts = n_experts\n",
        "        self.top_k = top_k\n",
        "        self.d_ff = d_ff\n",
        "        self.dropout = dropout\n",
        "        self.router_temp = router_temp\n",
        "        self.balance_loss_w = balance_loss_w\n",
        "        self.entropy_reg_w = entropy_reg_w\n",
        "        self.diversity_w = diversity_w\n",
        "        self.sticky_w = sticky_w\n",
        "        self.sup_router_w = sup_router_w\n",
        "        self.use_gumbel = use_gumbel\n",
        "\n",
        "class MoE(nn.Layer):\n",
        "    \"\"\"forward(x, domain_id=None) → (y, aux_loss)，支持 (B,T,D) 或 (N,D)\"\"\"\n",
        "    def __init__(self, d_model: int, cfg: MoEConfig):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.router = nn.Linear(d_model, cfg.n_experts)\n",
        "        self.experts = nn.LayerList([ExpertFFN(d_model, cfg.d_ff, cfg.dropout) for _ in range(cfg.n_experts)])\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(cfg.dropout)\n",
        "\n",
        "    def _router_probs(self, logits):\n",
        "        if self.cfg.use_gumbel and self.training:\n",
        "            u = paddle.uniform(logits.shape, min=1e-6, max=1-1e-6, dtype=logits.dtype)\n",
        "            g = -paddle.log(-paddle.log(u))\n",
        "            logits = logits + g\n",
        "        return F.softmax(logits / self.cfg.router_temp, axis=-1)\n",
        "\n",
        "    def forward(self, x, domain_id=None):\n",
        "        orig_shape = x.shape\n",
        "        if len(orig_shape) == 3:\n",
        "            B, T, D = orig_shape\n",
        "            X = x.reshape([B*T, D])\n",
        "        else:\n",
        "            X = x\n",
        "        N, D = X.shape\n",
        "\n",
        "        logits = self.router(X)             # (N,E)\n",
        "        probs = self._router_probs(logits)  # (N,E)\n",
        "        topk_val, topk_idx = paddle.topk(probs, k=self.cfg.top_k, axis=-1)  # (N,k)\n",
        "\n",
        "        # 专家并行输出\n",
        "        all_out = paddle.stack([e(X) for e in self.experts], axis=1)         # (N,E,D)\n",
        "\n",
        "        # === 使用 gather_nd 逐样本选择 top-k 专家 ===\n",
        "        arangeN = paddle.arange(N, dtype='int64')\n",
        "        picked_list = []\n",
        "        for i in range(self.cfg.top_k):\n",
        "            idx_i = topk_idx[:, i].astype('int64')                   # (N,)\n",
        "            idx_nd = paddle.stack([arangeN, idx_i], axis=1)          # (N,2) [sample, expert]\n",
        "            picked_i = paddle.gather_nd(all_out, idx_nd)             # (N,D)\n",
        "            picked_list.append(picked_i)\n",
        "        picked = paddle.stack(picked_list, axis=1)                   # (N,k,D)\n",
        "\n",
        "        # 归一化权重并加权\n",
        "        w = topk_val / (paddle.sum(topk_val, axis=-1, keepdim=True) + 1e-9)  # (N,k)\n",
        "        Y = paddle.sum(picked * w.unsqueeze(-1), axis=1)                      # (N,D)\n",
        "\n",
        "        Y = self.drop(Y)\n",
        "        Y = self.ln(Y + X)\n",
        "\n",
        "        # aux loss\n",
        "        aux = 0.0\n",
        "        if self.cfg.balance_loss_w > 0:\n",
        "            mean_prob = probs.mean(axis=0)\n",
        "            target = paddle.full_like(mean_prob, 1.0 / self.cfg.n_experts)\n",
        "            aux = aux + self.cfg.balance_loss_w * F.mse_loss(mean_prob, target)\n",
        "        if self.cfg.entropy_reg_w != 0.0:\n",
        "            ent = -paddle.sum(probs * (paddle.log(probs + 1e-9)), axis=1).mean()\n",
        "            aux = aux + self.cfg.entropy_reg_w * ent\n",
        "        if (domain_id is not None) and (self.cfg.sup_router_w > 0):\n",
        "            dom = domain_id.reshape([-1])[:N] % self.cfg.n_experts\n",
        "            aux = aux + self.cfg.sup_router_w * F.cross_entropy(logits, dom)\n",
        "        if self.cfg.diversity_w > 0 and self.cfg.n_experts > 1:\n",
        "            # 用 top-1 硬选择近似每个专家接收的样本\n",
        "            chosen = F.one_hot(topk_idx[:, 0], num_classes=self.cfg.n_experts).astype('float32')  # (N,E)\n",
        "            denom = chosen.sum(axis=0).clip(min=1.0).unsqueeze(-1)\n",
        "            means = (all_out * chosen.unsqueeze(-1)).sum(axis=0) / denom                           # (E,D)\n",
        "            sims = []\n",
        "            for i in range(self.cfg.n_experts):\n",
        "                for j in range(i+1, self.cfg.n_experts):\n",
        "                    si = F.normalize(means[i:i+1], axis=-1)\n",
        "                    sj = F.normalize(means[j:j+1], axis=-1)\n",
        "                    sims.append((si*sj).sum())\n",
        "            if sims:\n",
        "                aux = aux + self.cfg.diversity_w * paddle.stack(sims).mean()\n",
        "\n",
        "        if len(orig_shape) == 3:\n",
        "            Y = Y.reshape([B, T, D])\n",
        "        return Y, aux\n",
        "\n",
        "class MoEHead(nn.Layer):\n",
        "    \"\"\"单 token MoE 头，用于 fused/tabm 投影后的 (B, D)\"\"\"\n",
        "    def __init__(self, d_model=512, cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.moe = MoE(d_model, cfg or MoEConfig())\n",
        "    def forward(self, tok, domain_id=None):\n",
        "        y, aux = self.moe(tok.unsqueeze(1), domain_id=domain_id)  # (B,1,D)\n",
        "        return y.squeeze(1), aux\n",
        "\n",
        "# ====================== 自定义 Transformer Encoder（FFN 可替换为 MoE） ======================\n",
        "class TransformerEncoderLayerMoE(nn.Layer):\n",
        "    def __init__(self, d_model=512, nhead=8, d_ff=1024, dropout=0.1,\n",
        "                 use_moe: bool = True, moe_cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.use_moe = use_moe\n",
        "        self.self_attn = nn.MultiHeadAttention(embed_dim=d_model, num_heads=nhead, dropout=dropout)\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.do1 = nn.Dropout(dropout)\n",
        "        if use_moe:\n",
        "            self.moe = MoE(d_model, moe_cfg or MoEConfig(d_ff=d_ff, dropout=dropout))\n",
        "        else:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.LayerNorm(d_model),\n",
        "                nn.Linear(d_model, d_ff),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(d_ff, d_model),\n",
        "            )\n",
        "            self.do2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, domain_id=None):  # x: (B,T,D)\n",
        "        # Self-Attention (pre-norm) —— Paddle MHA 期望 (T,B,D)\n",
        "        h = self.ln1(x)\n",
        "        h = paddle.transpose(h, [1, 0, 2])          # (T,B,D)\n",
        "        sa = self.self_attn(h, h, h)                # (T,B,D)\n",
        "        sa = paddle.transpose(sa, [1, 0, 2])        # (B,T,D)\n",
        "        x = x + self.do1(sa)\n",
        "        aux = 0.0\n",
        "        if self.use_moe:\n",
        "            x, aux = self.moe(x, domain_id=domain_id)  # 残差+LN 在 MoE 内部\n",
        "        else:\n",
        "            x = x + self.do2(self.ffn(x))              # 残差在这里\n",
        "        return x, aux\n",
        "\n",
        "class TemporalTransformerFlexible(nn.Layer):\n",
        "    def __init__(self, d_model=512, nhead=8, num_layers=2, d_ff=1024, dropout=0.1,\n",
        "                 max_len=1024, use_moe: bool = True, moe_cfg: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        self.pos = SinusoidalPositionalEncoding(d_model, max_len=max_len)\n",
        "        self.layers = nn.LayerList([\n",
        "            TransformerEncoderLayerMoE(d_model, nhead, d_ff, dropout,\n",
        "                                       use_moe=use_moe, moe_cfg=moe_cfg)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "    def forward(self, x, domain_id=None):  # x: (B,T,D)\n",
        "        x = self.pos(x)\n",
        "        aux_total = 0.0\n",
        "        for layer in self.layers:\n",
        "            x, aux = layer(x, domain_id=domain_id)\n",
        "            aux_total = aux_total + aux\n",
        "        return x, aux_total\n",
        "\n",
        "# ====================== 多头注意力（支持 q from A, kv from B） ======================\n",
        "class MultiHeadCrossAttention(nn.Layer):\n",
        "    def __init__(self, d_model: int, nhead: int = 8, dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % nhead == 0\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "        self.d_head = d_model // nhead\n",
        "        self.Wq = nn.Linear(d_model, d_model)\n",
        "        self.Wk = nn.Linear(d_model, d_model)\n",
        "        self.Wv = nn.Linear(d_model, d_model)\n",
        "        self.proj = nn.Linear(d_model, d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.ln = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, q, kv):\n",
        "        B, Nq, D = q.shape\n",
        "        Nk = kv.shape[1]\n",
        "        q_lin = self.Wq(q); k_lin = self.Wk(kv); v_lin = self.Wv(kv)\n",
        "        def split_heads(t):\n",
        "            return t.reshape([B, -1, self.nhead, self.d_head]).transpose([0, 2, 1, 3])\n",
        "        qh = split_heads(q_lin); kh = split_heads(k_lin); vh = split_heads(v_lin)\n",
        "        scores = paddle.matmul(qh, kh, transpose_y=True) / math.sqrt(self.d_head)\n",
        "        attn = F.softmax(scores, axis=-1)\n",
        "        ctx = paddle.matmul(attn, vh)\n",
        "        ctx = ctx.transpose([0, 2, 1, 3]).reshape([B, Nq, D])\n",
        "        out = self.proj(ctx)\n",
        "        out = self.drop(out)\n",
        "        return self.ln(out + q)\n",
        "\n",
        "# ====================== 融合头（双向 Cross-Attn） ======================\n",
        "class BiModalCrossFusion(nn.Layer):\n",
        "    \"\"\"\n",
        "    输入：\n",
        "      video_seq: (B, T, D) —— Transformer 后的视频序列\n",
        "      tabm_tok:  (B, D)    —— TabM token\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model=512, nhead=8, dropout=0.1, fuse_hidden=512):\n",
        "        super().__init__()\n",
        "        self.ca_v_from_t = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.ca_t_from_v = MultiHeadCrossAttention(d_model, nhead, dropout)\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Linear(2 * d_model, fuse_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.out_dim = fuse_hidden\n",
        "\n",
        "    def forward(self, video_seq, tabm_tok):\n",
        "        B, T, D = video_seq.shape\n",
        "        # 池化视频时间维得到 token\n",
        "        v_tok = video_seq.mean(axis=1, keepdim=True)      # (B,1,D)\n",
        "        t_tok = tabm_tok.unsqueeze(1)                     # (B,1,D)\n",
        "        v_upd = self.ca_v_from_t(v_tok, t_tok)            # (B,1,D)\n",
        "        t_upd = self.ca_t_from_v(t_tok, video_seq)        # (B,1,D)\n",
        "        fused = paddle.concat([v_upd, t_upd], axis=-1)    # (B,1,2D)\n",
        "        fused = fused.squeeze(1)                          # (B,2D)\n",
        "        return self.fuse(fused)                           # (B, F)\n",
        "\n",
        "# ====================== 总模型（带三个 MoE 开关） ======================\n",
        "class TwoModalMultiLabelModel(nn.Layer):\n",
        "    def __init__(self,\n",
        "                 # 视频模态\n",
        "                 vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "                 # 结构化模态\n",
        "                 vec_dim=424,\n",
        "                 # 维度与结构\n",
        "                 d_model=512, nhead=2, n_trans_layers=2, trans_ff=1024,\n",
        "                 tabm_hidden=512, dropout=0.1, num_labels=4,\n",
        "                 # ===== MoE 开关 =====\n",
        "                 moe_temporal: bool = True,      # 时序 Transformer 的 FFN 位置\n",
        "                 moe_fused: bool = False,        # 融合 token 上的小型 MoE 头\n",
        "                 moe_tabm: bool = False,         # TabM 投影后\n",
        "                 # ===== MoE 超参（可传入自定义） =====\n",
        "                 moe_cfg_temporal: MoEConfig = None,\n",
        "                 moe_cfg_fused: MoEConfig = None,\n",
        "                 moe_cfg_tabm: MoEConfig = None):\n",
        "        super().__init__()\n",
        "        # A: 逐帧 ResNet18\n",
        "        self.frame_encoder = ResNet18FrameEncoder(in_channels=vid_channels)\n",
        "        # A: 时序 Transformer（可开/关 MoE）\n",
        "        self.temporal = TemporalTransformerFlexible(\n",
        "            d_model=d_model, nhead=nhead, num_layers=n_trans_layers,\n",
        "            d_ff=trans_ff, dropout=dropout, max_len=vid_frames,\n",
        "            use_moe=moe_temporal,\n",
        "            moe_cfg=moe_cfg_temporal or MoEConfig(\n",
        "                n_experts=8, top_k=1, d_ff=max(trans_ff, 2048), router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            )\n",
        "        )\n",
        "        # B: TabM（或你的 TabM）\n",
        "        self.tabm = TabMFeatureExtractor(vec_dim, d_hidden=tabm_hidden, dropout=dropout)\n",
        "        self.tabm_proj = nn.Linear(tabm_hidden, d_model)\n",
        "\n",
        "        # 可选：TabM 分支 MoE 头\n",
        "        self.moe_tabm = moe_tabm\n",
        "        if moe_tabm:\n",
        "            self.tabm_moe = MoEHead(d_model=d_model, cfg=moe_cfg_tabm or MoEConfig(\n",
        "                n_experts=6, top_k=1, d_ff=1024, router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            ))\n",
        "\n",
        "        # 融合：双向 Cross-Attention\n",
        "        self.fusion = BiModalCrossFusion(d_model=d_model, nhead=nhead, dropout=dropout, fuse_hidden=d_model)\n",
        "\n",
        "        # 可选：融合 token MoE 头\n",
        "        self.moe_fused = moe_fused\n",
        "        if moe_fused:\n",
        "            self.fused_moe = MoEHead(d_model=d_model, cfg=moe_cfg_fused or MoEConfig(\n",
        "                n_experts=6, top_k=1, d_ff=1024, router_temp=0.5,\n",
        "                balance_loss_w=0.005, entropy_reg_w=-0.005, diversity_w=1e-3\n",
        "            ))\n",
        "\n",
        "        # 分类头\n",
        "        self.head = nn.Linear(self.fusion.out_dim, num_labels)\n",
        "\n",
        "    # --- 新增：编码函数，导出融合前的 512 维特征（用于检索库） ---\n",
        "    def encode(self, x_video, x_vec, domain_id=None):\n",
        "        \"\"\"返回融合后的 512 维 token（分类头之前的表示），不经过最终 Linear。\"\"\"\n",
        "        B, T, C, H, W = x_video.shape\n",
        "        xvt = x_video.reshape([B * T, C, H, W])\n",
        "        f_frame = self.frame_encoder(xvt)                 # (B*T, 512)\n",
        "        f_seq = f_frame.reshape([B, T, -1])               # (B, T, 512)\n",
        "        z_vid, _ = self.temporal(f_seq, domain_id=domain_id)  # (B,T,512)\n",
        "        z_tabm = self.tabm(x_vec)\n",
        "        z_tabm = self.tabm_proj(z_tabm)                   # (B,512)\n",
        "        if self.moe_tabm:\n",
        "            z_tabm, _ = self.tabm_moe(z_tabm, domain_id=domain_id)\n",
        "        fused = self.fusion(z_vid, z_tabm)                # (B,512)\n",
        "        if self.moe_fused:\n",
        "            fused, _ = self.fused_moe(fused, domain_id=domain_id)\n",
        "        return fused                                      # (B,512)\n",
        "\n",
        "    def forward(self, x_video, x_vec, domain_id=None):\n",
        "        fused = self.encode(x_video, x_vec, domain_id=domain_id)  # (B,512)\n",
        "        logits = self.head(fused)                                 # (B,4)\n",
        "        # 为了兼容旧接口，这里返回的 aux 为 0（MoE 的 aux 已在 temporal/tabm_moe/fused_moe 内部求和并丢弃）\n",
        "        # 如果你想把 MoE 的 aux 在训练里也加入，可把 encode 拆回 forward 的各步并返回累积 aux。\n",
        "        aux_placeholder = paddle.to_tensor(0.0, dtype='float32')\n",
        "        return logits, aux_placeholder\n",
        "\n",
        "# ====================== 指标与训练循环（兼容 aux_loss） ======================\n",
        "def f1_per_class(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-9) -> Tuple[np.ndarray, float, float]:\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    N, C = y_true.shape\n",
        "    f1_c = np.zeros(C, dtype=np.float32)\n",
        "    for c in range(C):\n",
        "        yt, yp = y_true[:, c], y_pred[:, c]\n",
        "        tp = np.sum((yt == 1) & (yp == 1))\n",
        "        fp = np.sum((yt == 0) & (yp == 1))\n",
        "        fn = np.sum((yt == 1) & (yp == 0))\n",
        "        prec = tp / (tp + fp + eps)\n",
        "        rec  = tp / (tp + fn + eps)\n",
        "        f1_c[c] = 2 * prec * rec / (prec + rec + eps)\n",
        "    macro_f1 = float(np.mean(f1_c))\n",
        "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "    prec = tp / (tp + fp + 1e-9)\n",
        "    rec  = tp / (tp + fn + 1e-9)\n",
        "    micro_f1 = 2 * prec * rec / (prec + rec + 1e-9)\n",
        "    return f1_c, macro_f1, float(micro_f1)\n",
        "\n",
        "def average_precision_micro(y_true: np.ndarray, y_prob: np.ndarray, num_thresholds: int = 101) -> float:\n",
        "    thresholds = np.linspace(0.0, 1.0, num_thresholds)\n",
        "    precision, recall = [], []\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(np.float32)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
        "        p = tp / (tp + fp + 1e-9)\n",
        "        r = tp / (tp + fn + 1e-9)\n",
        "        precision.append(p); recall.append(r)\n",
        "    order = np.argsort(recall)\n",
        "    recall = np.array(recall)[order]\n",
        "    precision = np.array(precision)[order]\n",
        "    return float(np.trapz(precision, recall))\n",
        "\n",
        "LAMBDA_MOE = 0.0  # 这里的 forward 返回 aux=0（如需把 MoE aux 算进去，可按上一版做法）\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer,\n",
        "                    pos_weight: Optional[paddle.Tensor] = None,\n",
        "                    clip_grad_norm: Optional[float] = None):\n",
        "    model.train()\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits, _ = model(x_vid.astype('float32'), x_vec.astype('float32'))\n",
        "        if pos_weight is not None:\n",
        "            cls = F.binary_cross_entropy_with_logits(logits, y.astype('float32'), pos_weight=pos_weight)\n",
        "        else:\n",
        "            cls = F.binary_cross_entropy_with_logits(logits, y.astype('float32'))\n",
        "        loss = cls  # + LAMBDA_MOE * aux  # 此版本不叠加 MoE aux\n",
        "        loss.backward()\n",
        "        if clip_grad_norm is not None:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad_norm)\n",
        "        optimizer.step()\n",
        "        optimizer.clear_grad()\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "    return total_loss / max(1, total_batches)\n",
        "\n",
        "# ====================== 检索增强：构建训练库 & 测试时融合 ======================\n",
        "class Retriever:\n",
        "    \"\"\"\n",
        "    检索库：\n",
        "      - keys: 训练集的特征 (N,D) —— 取模型 encode() 的融合特征\n",
        "      - labels: 训练集的标签 (N,C)\n",
        "    推理：\n",
        "      - 给定测试特征 (B,D)，计算与 keys 的相似度，取 top-k\n",
        "      - 得到邻居标签的加权均值 p_knn，按 alpha 融合到模型概率\n",
        "    \"\"\"\n",
        "    def __init__(self, sim_metric: str = 'cos', k: int = 8, alpha: float = 0.3, tau: float = 1.0):\n",
        "        \"\"\"\n",
        "        sim_metric: 'cos' or 'l2'\n",
        "        k: 近邻数\n",
        "        alpha: 融合系数，p_final = (1-alpha)*p_model + alpha*p_knn\n",
        "        tau: 温度（用于 l2 的 softmax(-d/tau) 或 cos 的 softmax(sim/tau)）\n",
        "        \"\"\"\n",
        "        assert sim_metric in ['cos', 'l2']\n",
        "        self.sim_metric = sim_metric\n",
        "        self.k = k\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "        self.keys = None     # (N,D)\n",
        "        self.labels = None   # (N,C)\n",
        "\n",
        "    @paddle.no_grad()\n",
        "    def build(self, model: nn.Layer, loader: DataLoader):\n",
        "        model.eval()\n",
        "        feats, labs = [], []\n",
        "        for x_vid, x_vec, y in loader:\n",
        "            f = model.encode(x_vid.astype('float32'), x_vec.astype('float32'))  # (B,512)\n",
        "            feats.append(f.numpy())\n",
        "            labs.append(y.numpy())\n",
        "        self.keys = paddle.to_tensor(np.concatenate(feats, axis=0)).astype('float32')   # (N,D)\n",
        "        self.labels = paddle.to_tensor(np.concatenate(labs, axis=0)).astype('float32')  # (N,C)\n",
        "        # 预归一化（cos 相似度更快；l2 也可复用）\n",
        "        self.keys_norm = F.normalize(self.keys, axis=-1)\n",
        "\n",
        "    @paddle.no_grad()\n",
        "    def query_and_fuse(self, model_probs: paddle.Tensor, test_feat: paddle.Tensor) -> paddle.Tensor:\n",
        "        \"\"\"\n",
        "        model_probs: (B,C)   —— 模型自身概率（sigmoid后的）\n",
        "        test_feat:   (B,D)   —— 模型 encode 导出的融合特征\n",
        "        return:      (B,C)   —— 融合后的概率\n",
        "        \"\"\"\n",
        "        assert self.keys is not None, \"Call build() before query.\"\n",
        "        B, D = test_feat.shape\n",
        "        # 相似度\n",
        "        if self.sim_metric == 'cos':\n",
        "            q = F.normalize(test_feat, axis=-1)                # (B,D)\n",
        "            sim = paddle.matmul(q, self.keys_norm, transpose_y=True)  # (B,N)\n",
        "            w = F.softmax(sim / self.tau, axis=-1)             # (B,N)\n",
        "        else:  # 'l2'\n",
        "            # ||q-k||^2 = q^2 + k^2 - 2 q·k\n",
        "            q2 = paddle.sum(test_feat * test_feat, axis=-1, keepdim=True)          # (B,1)\n",
        "            k2 = paddle.sum(self.keys * self.keys, axis=-1, keepdim=True).transpose([1,0])  # (1,N)\n",
        "            dot = paddle.matmul(test_feat, self.keys, transpose_y=True)            # (B,N)\n",
        "            dist2 = q2 + k2 - 2.0 * dot                                            # (B,N)\n",
        "            w = F.softmax(-dist2 / self.tau, axis=-1)                              # (B,N)\n",
        "\n",
        "        # 取 top-k（可选：先 topk 再归一化，避免长尾干扰）\n",
        "        topk_val, topk_idx = paddle.topk(w, k=min(self.k, w.shape[1]), axis=-1)    # (B,k)\n",
        "        # gather labels\n",
        "        N, C = self.labels.shape\n",
        "        b_idx = paddle.arange(B, dtype='int64').unsqueeze(-1).tile([1, topk_val.shape[1]])  # (B,k)\n",
        "        # 先 gather 权重对应的 labels\n",
        "        picked_labels = paddle.gather(self.labels, topk_idx.reshape([-1]), axis=0)          # (B*k, C)\n",
        "        picked_labels = picked_labels.reshape([B, -1, C])                                   # (B,k,C)\n",
        "        w_norm = topk_val / (paddle.sum(topk_val, axis=-1, keepdim=True) + 1e-9)            # (B,k)\n",
        "        p_knn = paddle.sum(picked_labels * w_norm.unsqueeze(-1), axis=1)                    # (B,C)\n",
        "\n",
        "        # 概率融合\n",
        "        p_final = (1.0 - self.alpha) * model_probs + self.alpha * p_knn\n",
        "        return p_final.clip(1e-6, 1-1e-6)\n",
        "\n",
        "@paddle.no_grad()\n",
        "def evaluate(model, loader, threshold: float = 0.5,\n",
        "             retriever: Optional[Retriever] = None):\n",
        "    \"\"\"\n",
        "    若 retriever 不为 None：在测试时做 kNN 检索并与模型概率融合。\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    total_loss, total_batches = 0.0, 0\n",
        "    for x_vid, x_vec, y in loader:\n",
        "        logits, _ = model(x_vid.astype('float32'), x_vec.astype('float32'))\n",
        "        prob = F.sigmoid(logits)  # (B,C)\n",
        "\n",
        "        if retriever is not None:\n",
        "            feat = model.encode(x_vid.astype('float32'), x_vec.astype('float32'))     # (B,D)\n",
        "            prob = retriever.query_and_fuse(prob, feat)                                # (B,C)\n",
        "\n",
        "        loss = F.binary_cross_entropy(prob, y.astype('float32'))  # 用概率计算 eval loss\n",
        "        ys.append(y.numpy()); ps.append(prob.numpy())\n",
        "        total_loss += float(loss); total_batches += 1\n",
        "\n",
        "    y_true = np.concatenate(ys, axis=0)\n",
        "    y_prob = np.concatenate(ps, axis=0)\n",
        "    y_pred = (y_prob >= threshold).astype(np.float32)\n",
        "    per_f1, macro_f1, micro_f1 = f1_per_class(y_true, y_pred)\n",
        "    ap_micro = average_precision_micro(y_true, y_prob)\n",
        "    return {\n",
        "        \"loss\": total_loss / max(1, total_batches),\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"per_class_f1\": per_f1.tolist(),\n",
        "        \"micro_AP\": ap_micro\n",
        "    }\n",
        "\n",
        "# ====================== 合成数据集（可替换为真实数据） ======================\n",
        "class ToyTwoModalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    返回：\n",
        "      x_video: (T=36, C=20, H=20, W=20)\n",
        "      x_vec:   (424,)\n",
        "      y:       (4,)  0/1\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, seed: int = 0):\n",
        "        super().__init__()\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.n = n\n",
        "        self.video = rng.normal(size=(n, 36, 20, 20, 20)).astype('float32')\n",
        "        self.vec   = rng.normal(size=(n, 424)).astype('float32')\n",
        "\n",
        "        # 造标签：对视频先在 H/W 上均值，再在 T 上均值 → (n, C=20)\n",
        "        vid_hw  = self.video.mean(axis=(3, 4))   # (n, T, C)\n",
        "        vid_avg = vid_hw.mean(axis=1)            # (n, C)\n",
        "        Wv = rng.normal(size=(20, 4))            # C→4\n",
        "        Wt = rng.normal(size=(424, 4))           # 424→4\n",
        "        logits = vid_avg @ Wv + self.vec @ Wt + rng.normal(scale=0.5, size=(n, 4))\n",
        "        probs  = 1.0 / (1.0 + np.exp(-logits))\n",
        "        self.y = (probs > 0.5).astype('float32')\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.video[idx], self.vec[idx], self.y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n\n",
        "\n",
        "# ====================== 训练入口（可直接运行） ======================\n",
        "if __name__ == \"__main__\":\n",
        "    paddle.seed(2025)\n",
        "    # 数据\n",
        "    train_ds = ToyTwoModalDataset(n=128, seed=42)\n",
        "    val_ds   = ToyTwoModalDataset(n=32,  seed=233)\n",
        "\n",
        "    def collate_fn(batch):\n",
        "        vids, vecs, ys = zip(*batch)\n",
        "        return (paddle.to_tensor(np.stack(vids, 0)),   # (B,T,C,H,W)\n",
        "                paddle.to_tensor(np.stack(vecs, 0)),   # (B,424)\n",
        "                paddle.to_tensor(np.stack(ys, 0)))     # (B,4)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, drop_last=False, collate_fn=collate_fn)\n",
        "    val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, drop_last=False, collate_fn=collate_fn)\n",
        "\n",
        "    # 类别不平衡权重（可选）\n",
        "    y_train = np.stack([y for _, _, y in train_ds], 0)\n",
        "    pos_ratio = np.clip(y_train.mean(axis=0), 1e-3, 1-1e-3)\n",
        "    pos_weight = paddle.to_tensor(((1-pos_ratio)/pos_ratio).astype('float32'))  # (4,)\n",
        "\n",
        "    # === 模型（MoE 开关按需） ===\n",
        "    model = TwoModalMultiLabelModel(\n",
        "        vid_channels=20, vid_h=20, vid_w=20, vid_frames=36,\n",
        "        vec_dim=424,\n",
        "        d_model=512, nhead=2, n_trans_layers=2, trans_ff=1024,\n",
        "        tabm_hidden=512, dropout=0.1,\n",
        "        num_labels=4,\n",
        "        moe_temporal=True,     # FFN 位置 MoE\n",
        "        moe_fused=False,       # 融合处 MoE\n",
        "        moe_tabm=False         # TabM 处 MoE\n",
        "    )\n",
        "    optimizer = paddle.optimizer.Adam(learning_rate=3e-4, parameters=model.parameters())\n",
        "\n",
        "    # 训练（演示用）\n",
        "    best_macro_f1, best = -1.0, None\n",
        "    for ep in range(1, 3+1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer,\n",
        "                                     pos_weight=pos_weight, clip_grad_norm=1.0)\n",
        "        val_metrics = evaluate(model, val_loader, threshold=0.5, retriever=None)\n",
        "        print(f\"[Epoch {ep:02d}] train_loss={train_loss:.4f} | \"\n",
        "              f\"val_loss={val_metrics['loss']:.4f} | \"\n",
        "              f\"macro_f1={val_metrics['macro_f1']:.4f} | \"\n",
        "              f\"micro_f1={val_metrics['micro_f1']:.4f} | \"\n",
        "              f\"per_class_f1={val_metrics['per_class_f1']} | \"\n",
        "              f\"micro_AP={val_metrics['micro_AP']:.4f}\")\n",
        "        if val_metrics[\"macro_f1\"] > best_macro_f1:\n",
        "            best_macro_f1 = val_metrics[\"macro_f1\"]\n",
        "            best = {k: v.clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "    if best is not None:\n",
        "        model.set_state_dict(best)\n",
        "        print(f\"Loaded best state with macro_f1={best_macro_f1:.4f}\")\n",
        "\n",
        "    # === 构建检索库（使用训练集） ===\n",
        "    retr = Retriever(sim_metric='cos', k=8, alpha=0.3, tau=0.5)  # 可改 'l2'\n",
        "    retr.build(model, DataLoader(train_ds, batch_size=8, shuffle=False, collate_fn=collate_fn))\n",
        "\n",
        "    # === 测试时启用检索增强 ===\n",
        "    val_metrics_knn = evaluate(model, val_loader, threshold=0.5, retriever=retr)\n",
        "    print(f\"[RkNN] val_loss={val_metrics_knn['loss']:.4f} | \"\n",
        "          f\"macro_f1={val_metrics_knn['macro_f1']:.4f} | \"\n",
        "          f\"micro_f1={val_metrics_knn['micro_f1']:.4f} | \"\n",
        "          f\"per_class_f1={val_metrics_knn['per_class_f1']} | \"\n",
        "          f\"micro_AP={val_metrics_knn['micro_AP']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6m8tTnwSSYC",
        "outputId": "b7bfaa2f-71fa-4945-c8b4-b4f586fd0fdf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/paddle/nn/layer/norm.py:818: UserWarning: When training, we now always track global mean and variance.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2448755935.py:419: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
            "  return float(np.trapz(precision, recall))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 01] train_loss=0.8949 | val_loss=0.7680 | macro_f1=0.4306 | micro_f1=0.5255 | per_class_f1=[0.5454545617103577, 0.5405405163764954, 0.6363636255264282, 0.0] | micro_AP=0.4448\n",
            "[Epoch 02] train_loss=0.5957 | val_loss=0.9367 | macro_f1=0.4620 | micro_f1=0.5414 | per_class_f1=[0.4444444477558136, 0.7450980544090271, 0.5333333611488342, 0.125] | micro_AP=0.5133\n",
            "[Epoch 03] train_loss=0.3141 | val_loss=1.1780 | macro_f1=0.3715 | micro_f1=0.4158 | per_class_f1=[0.125, 0.5, 0.6000000238418579, 0.260869562625885] | micro_AP=0.5041\n",
            "Loaded best state with macro_f1=0.4620\n",
            "[RkNN] val_loss=0.8189 | macro_f1=0.4900 | micro_f1=0.5390 | per_class_f1=[0.4000000059604645, 0.7599999904632568, 0.5142857432365417, 0.2857142984867096] | micro_AP=0.4978\n"
          ]
        }
      ]
    }
  ]
}